<!DOCTYPE html>
<html lang="zh">
<head><meta name="generator" content="Hexo 3.8.0">
    <meta charset="utf-8">
<title>ÁªèÂÖ∏Êú∫Âô®Â≠¶‰π†Á¨îËÆ∞ - little_sun&#39;s blog</title>
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">



    <meta name="description" content="Êú¨Êñá‰∏∫Ê∏ÖÂçéÂ§ßÂ≠¶‚ÄùÊ®°ÂºèËØÜÂà´‰∏éÊú∫Âô®Â≠¶‰π†‚ÄùËØæÁ®ãÁöÑÂ§ç‰π†Á¨îËÆ∞„ÄÇ">
<meta name="keywords" content="Machine Learning">
<meta property="og:type" content="article">
<meta property="og:title" content="ÁªèÂÖ∏Êú∫Âô®Â≠¶‰π†Á¨îËÆ∞">
<meta property="og:url" content="http://www.zcysky.com/2024/06/09/Trad-ML/index.html">
<meta property="og:site_name" content="little_sun&#39;s blog">
<meta property="og:description" content="Êú¨Êñá‰∏∫Ê∏ÖÂçéÂ§ßÂ≠¶‚ÄùÊ®°ÂºèËØÜÂà´‰∏éÊú∫Âô®Â≠¶‰π†‚ÄùËØæÁ®ãÁöÑÂ§ç‰π†Á¨îËÆ∞„ÄÇ">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="https://raw.githubusercontent.com/zcy05331/image-saver/refs/heads/main/Trad_ML/HMM%20Chain.png">
<meta property="og:updated_time" content="2024-10-18T11:13:47.610Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="ÁªèÂÖ∏Êú∫Âô®Â≠¶‰π†Á¨îËÆ∞">
<meta name="twitter:description" content="Êú¨Êñá‰∏∫Ê∏ÖÂçéÂ§ßÂ≠¶‚ÄùÊ®°ÂºèËØÜÂà´‰∏éÊú∫Âô®Â≠¶‰π†‚ÄùËØæÁ®ãÁöÑÂ§ç‰π†Á¨îËÆ∞„ÄÇ">
<meta name="twitter:image" content="https://raw.githubusercontent.com/zcy05331/image-saver/refs/heads/main/Trad_ML/HMM%20Chain.png">





<link rel="icon" href="/favicon.ico">


<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bulma@0.7.2/css/bulma.css">
<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.6.1/css/all.css">
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Ubuntu:400,600|Source+Code+Pro">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css">


    
    
    
    <style>body>.footer,body>.navbar,body>.section{opacity:0}</style>
    

    
    
    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css">
    

    
    

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/outdatedbrowser@1.1.5/outdatedbrowser/outdatedbrowser.min.css">


    
    
    
    

<link rel="stylesheet" href="/css/back-to-top.css">


    
    

    
    
    
    

    
    
<link rel="stylesheet" href="/css/progressbar.css">
<script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script>

    


<link rel="stylesheet" href="/css/style.css">
</head>
<body class="is-2-column">
    <nav class="navbar navbar-main">
    <div class="container">
        <div class="navbar-brand is-flex-center">
            <a class="navbar-item navbar-logo" href="/">
            
                <!-- <img src="/images/logo.png" alt="ÁªèÂÖ∏Êú∫Âô®Â≠¶‰π†Á¨îËÆ∞" height="28"> -->
                <span class="navbar-title"> little_sun's blog </span>
            
            </a>
        </div>
        <div class="navbar-menu">
            
            <div class="navbar-start">
                
                <a class="navbar-item" href="/">È¶ñÈ°µ</a>
                
                <a class="navbar-item" href="/categories">ÂàÜÁ±ª</a>
                
                <a class="navbar-item" href="/archives">ÂΩíÊ°£</a>
                
                <a class="navbar-item" href="/tags">Ê†áÁ≠æ</a>
                
                <a class="navbar-item" href="/friends">ÂèãÈìæ</a>
                
                <a class="navbar-item" href="/summary">Summary</a>
                
            </div>
            
            <div class="navbar-end">
                
                
                
                <a class="navbar-item search" title="ÊêúÁ¥¢" href="javascript:;">
                    <i class="fas fa-search"></i>
                </a>
                
            </div>
        </div>
    </div>
</nav>
    
    <section class="section">
        <div class="container">
            <div class="columns">
                <div class="column my-content is-8-tablet is-8-desktop is-8-widescreen has-order-2 column-main"><div class="card">
    
    <div class="card-content article
         
    ">
        
        <div class="my-title  my-post-title ">
            <h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal">
                
                    ÁªèÂÖ∏Êú∫Âô®Â≠¶‰π†Á¨îËÆ∞
                
            </h1>
            <div class="level article-meta is-size-7 is-mobile is-overflow-x-auto">
                <div class="level-left">
                    <i class="far fa-clock"></i>
                    <time class="level-item has-text-grey" datetime="2024-06-09T06:25:08.000Z">
                        2024-06-09
                    </time>
                    <i class="far fa-folder"></i>
                    
                        <div class="level-item">
                            <a class="has-link-grey -link" href="/categories/Notes/">Notes</a>
                        </div>
                    
                    <i class="far fa-edit"></i>
                    
                        <span class="level-item has-text-grey">
                            8105 Words
                        </span>
                    
                </div>
            </div>
        </div>
        
        <div class="content">
            <p>Êú¨Êñá‰∏∫Ê∏ÖÂçéÂ§ßÂ≠¶‚ÄùÊ®°ÂºèËØÜÂà´‰∏éÊú∫Âô®Â≠¶‰π†‚ÄùËØæÁ®ãÁöÑÂ§ç‰π†Á¨îËÆ∞„ÄÇ</p>
<a id="more"></a>
<h2 id="Evaluation-Metric"><a href="#Evaluation-Metric" class="headerlink" title="Evaluation Metric"></a>Evaluation Metric</h2><script type="math/tex; mode=display">
\begin{aligned}
\text{Accuracy} &= \frac{\text{TP+TN}}{\text{TP+FP+TN+FN}} \newline
\text{Precision} &= \frac{\text{TP}}{\text{TP+FP}} \newline
\text{Recall} &= \text{Sensitivity} = \frac{\text{TP}}{\text{TP+FN}} \newline
\text{Specificity} &= \frac{\text{TN}}{\text{TN+FP}} \newline
\text{Type-I Error} &= \frac{\text{FP}}{\text{TP+FN}} = 1 - \text{Sensitivity} \newline
\text{Type-II Error} &= \frac{\text{FN}}{\text{TN+FP}} = 1 - \text{Specificity} \newline
\end{aligned}</script><h2 id="k-NN"><a href="#k-NN" class="headerlink" title="k-NN"></a>k-NN</h2><h3 id="Nearest-Neighbor"><a href="#Nearest-Neighbor" class="headerlink" title="Nearest Neighbor"></a>Nearest Neighbor</h3><p>For a new instance $x‚Äô$, its class $\omega‚Äô$ can be predicted by:</p>
<script type="math/tex; mode=display">
\omega' = \omega_i, \text{ where } i = \underset{j}{\arg\min} \, \delta(x', x_j)</script><h3 id="k-Nearest-Neighbor"><a href="#k-Nearest-Neighbor" class="headerlink" title="k-Nearest Neighbor"></a>k-Nearest Neighbor</h3><p>For a new instance $x$, define $g_i(x)$ as: the number of $x$‚Äôs k-nearest instances belonging to the class $\omega_i$.</p>
<p>Then the new instance‚Äôs class $\omega‚Äô$ can be predicted as:</p>
<script type="math/tex; mode=display">
\omega' = \omega_j,\text{ where }j = \underset{i}{\arg\max} \, g_i(x)</script><h3 id="k-NN-Improvements"><a href="#k-NN-Improvements" class="headerlink" title="k-NN Improvements"></a>k-NN Improvements</h3><h4 id="Branch-Bound-Algorithm"><a href="#Branch-Bound-Algorithm" class="headerlink" title="Branch-Bound Algorithm"></a>Branch-Bound Algorithm</h4><p>Use tree structure to reduce calculation.</p>
<h4 id="Edit-Nearest-Neighbor"><a href="#Edit-Nearest-Neighbor" class="headerlink" title="Edit Nearest Neighbor"></a>Edit Nearest Neighbor</h4><p>Delete nodes that may be misguiding from the training instance set.</p>
<h4 id="Condensed-Nearest-Neighbor"><a href="#Condensed-Nearest-Neighbor" class="headerlink" title="Condensed Nearest Neighbor"></a>Condensed Nearest Neighbor</h4><p>Delete nodes that are far away from decision boundaries.</p>
<h3 id="The-Curse-of-Dimensionality"><a href="#The-Curse-of-Dimensionality" class="headerlink" title="The Curse of Dimensionality"></a>The Curse of Dimensionality</h3><h4 id="Problem"><a href="#Problem" class="headerlink" title="Problem"></a>Problem</h4><ul>
<li>Many irrelevant attributes</li>
<li>In high-dimensional spaces, most points are equally far from each other.</li>
</ul>
<h4 id="Solution"><a href="#Solution" class="headerlink" title="Solution"></a>Solution</h4><ul>
<li>Dimensionality reduction techniques</li>
<li>manifold learning</li>
<li>Feature selection</li>
<li>Use prior knowledge</li>
</ul>
<h2 id="Linear-Regression-Multivariate-ver"><a href="#Linear-Regression-Multivariate-ver" class="headerlink" title="Linear Regression (Multivariate ver.)"></a>Linear Regression (Multivariate ver.)</h2><p>For a multivariate linear regression, the function becomes $ y_i = \mathbf{w}^{\rm T}\mathbf{x}_i $ , where $ \mathbf{x}_i = (1, x_i^1, \cdots, x_i^d)^{\rm T}\in \mathbb{R}^{d+1}, \mathbf{w} = (w_0, w_1, \cdots, w_d)^{\rm T} \in \mathbb{R}^{d+1}$, We adjust the values of $\mathbf{w}$ to find the equation that gives the best fitting line $f(x) = \mathbf{w}^{\rm T}\mathbf{x}$</p>
<p>We find the best $ \mathbf{w}^*$ using the Mean Squared Loss: $\ell(f(\mathbf x, y)) = \min\limits_{\mathbf w} \frac{1}{N} \sum_{i = 1}^N (f(\mathbf x_i) - y_i)^2 = \min \limits_{\mathbf w} \frac{1}{N}(\mathbf {Xw-y})^{\rm T}(\mathbf {Xw-y})$</p>
<p>So that $ \mathbf{w}^{\star} $ must satisfy $ \mathbf {X^{\rm T}} \mathbf {Xw^{\star}} = \mathbf X^{\rm T}\mathbf y$ , so we get $\mathbf{w^{\star}} = (\mathbf {X^{\rm T}X})^{-1}\mathbf X^{\rm T}\mathbf y$ or $\mathbf{w^{\star}} = (\mathbf {X^{\rm T}X} + \lambda \mathbf I)^{-1}\mathbf X^{\rm T}\mathbf y$ (Ridge Regression)</p>
<h2 id="Linear-Discriminant-Analysis"><a href="#Linear-Discriminant-Analysis" class="headerlink" title="Linear Discriminant Analysis"></a>Linear Discriminant Analysis</h2><p>project input vector $\mathbf x \in \mathbb{R}^{d+1}$ down to a 1-dimensional subspace with projection vector $\mathbf w$</p>
<p>The problem is how do we find the good projection vector? We have Fisher‚Äôs Criterion, that is to maximize a function that represents the difference between-class means, which is normalized by a measure of the within-class scatter.</p>
<p>We have <strong>between-class scatter</strong> $\tilde{S}_b = (\tilde{m}_1 - \tilde{m}_2)^2$, where $\tilde{m}_i$ is the mean for the i-th class. Also we have <strong>within-class scatter</strong> $\tilde{S}_i=\sum_{y_j \in \mathscr{y}_{i}} (y_j - \tilde{m}_i)^2$, then we have <strong>total within-class scatter</strong> $\tilde{S}_w = \tilde{S}_1+ \tilde{S}_2$. Combining the 2 expressions, the new objective function will be $J_F(\mathbf w) = \frac{\tilde{S}_b}{\tilde{S}_w}$</p>
<p>We have $\tilde{S}_b = (\tilde{m}_1 - \tilde{m}_2)^2 = (\mathbf w^{\rm T} \mathbf m_1 - \mathbf w^{\rm T} \mathbf m_2)^2 = \mathbf w^{\rm T} (\mathbf m_1 - \mathbf m_2)(\mathbf m_1 - \mathbf m_2)^{\rm T} \mathbf w = \mathbf w^{\rm T} \mathbf S_b \mathbf w$, also $\tilde{S}_w = \mathbf w^{\rm T} \mathbf S_w \mathbf w$, so now optimize objective function $J_F$ w.r.t $\mathbf w$:</p>
<script type="math/tex; mode=display">
\max\limits_{\mathbf w} J_F(\mathbf w) = \max \limits_ {\mathbf w} \frac{\mathbf w^{\rm T} \mathbf S_b \mathbf w}{\mathbf w^{\rm T} \mathbf S_w \mathbf w}</script><p>Use Lagrange Multiplier Method we obtain: $\lambda w^{\star} = \mathbf{S}_W^{-1} (\mathbf m_1 - \mathbf m_2)(\mathbf m_1 - \mathbf m_2)^{\rm T}\mathbf w^{\star}$, since we only care about the direction of $\mathbf w^*$ and $(\mathbf m_1 - \mathbf m_2)^{\rm T}\mathbf w^{\star}$ is scalar, thus we obtain $w^{\star} = \mathbf{S}_W^{-1} (\mathbf m_1 - \mathbf m_2)$</p>
<h2 id="Logistic-Regression"><a href="#Logistic-Regression" class="headerlink" title="Logistic Regression"></a>Logistic Regression</h2><p>Logistic regression is a statistical method used for binary classification, which means it is used to predict the probability of one of two possible outcomes. Unlike linear regression, which predicts a continuous output, logistic regression predicts a discrete outcome (0 or 1, yes or no, true or false, etc.).</p>
<h3 id="Key-Concepts"><a href="#Key-Concepts" class="headerlink" title="Key Concepts"></a>Key Concepts</h3><ol>
<li><p><strong>Odds and Log-Odds:</strong></p>
<ul>
<li><strong>Odds</strong>: The odds of an event are the ratio of the probability that the event will occur to the probability that it will not occur.<script type="math/tex; mode=display">
\text{Odds} = \frac{P(y=1)}{P(y=0)}</script></li>
<li><strong>Log-Odds (Logit)</strong>: The natural logarithm of the odds.<script type="math/tex; mode=display">
\text{Log-Odds} = \log\left(\frac{P(y=1)}{P(y=0)}\right)</script></li>
</ul>
</li>
<li><p><strong>Logistic Function (Sigmoid Function):</strong></p>
<ul>
<li>The logistic function maps any real-valued number into the range (0, 1), making it suitable for probability predictions.<script type="math/tex; mode=display">
\sigma(z) = \frac{1}{1 + e^{-z}}</script></li>
<li>In logistic regression, $ z $ is a linear combination of the input features.<script type="math/tex; mode=display">
z = w^T x + b</script></li>
</ul>
</li>
<li><p><strong>Model Equation:</strong></p>
<ul>
<li>The probability of the positive class (e.g., $ y=1 $) is given by the logistic function applied to the linear combination of the features.<script type="math/tex; mode=display">
P(y=1|x) = \sigma(w^T x + b) = \frac{1}{1 + e^{-(w^T x + b)}}</script></li>
<li>The probability of the negative class (e.g., $ y=0 $) is:<script type="math/tex; mode=display">
P(y=0|x) = 1 - P(y=1|x)</script></li>
</ul>
</li>
<li><p><strong>Decision Boundary:</strong></p>
<ul>
<li>To make a binary decision, we typically use a threshold (commonly 0.5). If $ P(y=1|x) $ is greater than 0.5, we predict the positive class; otherwise, we predict the negative class.</li>
</ul>
</li>
</ol>
<h3 id="Training-the-Model"><a href="#Training-the-Model" class="headerlink" title="Training the Model"></a>Training the Model</h3><p>We use MLE(Maximum Likelihood Estimation) for logistic regression:  </p>
<script type="math/tex; mode=display">
\max_{\mathbf w} \prod_{i=1}^{N} \left[ \theta(w^T x)^{\mathbf 1(y_i=1)} \times (1 - \theta(w^T x))^{\mathbf 1(y_i=0)} \right]</script><p>Applying negative log to the likelihood function, we obtain the log-likelihood for logistic regression. =</p>
<script type="math/tex; mode=display">
\min_{\mathbf w} J(\mathbf w) = \min\limits_{\mathbf w} - \sum_{i=1}^{N} \left\{ y_i \log \left( \frac{e^{\mathbf w^{\rm T} \mathbf x_i}}{1 + e^{\mathbf w^{\rm T} \mathbf x_i}} \right) + (1 - y_i) \log \left( 1 - \frac{e^{\mathbf w^{\rm T} \mathbf x_i}}{1 + e^{\mathbf w^{\rm T} \mathbf x_i}} \right) \right\}</script><p>Substituting $y_i \in \{0, +1\}$ with $\tilde y_i \in \{-1, +1\}$, and noting that $\theta(-s) + \theta(s) = 1$, we can simplify the previous expression:</p>
<script type="math/tex; mode=display">
\min_w J(w) = \min_{\mathbf w} \sum_{i = 1}^N \log(1 + e^{-\tilde y_i \mathbf w ^ {\rm T}\mathbf x_i})</script><p>This is called the Cross Entropy Loss.</p>
<h3 id="Generalization-to-K-classes"><a href="#Generalization-to-K-classes" class="headerlink" title="Generalization to K-classes"></a>Generalization to K-classes</h3><p>The generalized version of logistic regression is called <strong>Softmax Regression</strong>.</p>
<p>The probability of an input $x$ being class $k$ is denoted as:  </p>
<script type="math/tex; mode=display">
P(y = k | x; \mathbf{W}) = \frac{e^{\mathbf w_k^{\rm T} x}}{\sum_{i=1}^{K} e^{\mathbf w_i^{\rm T} x}}</script><p>In multiclass, the likelihood function can be written as:</p>
<script type="math/tex; mode=display">
\max_{w_1, w_2, \ldots, w_k} \prod_{i=1}^{N} \prod_{k=0}^{K} P(y_i = k | x_i; \mathbf{W})^{\mathbf 1(y_i = k)}</script><p>We can use the minimum negative log-likehood estimation:  </p>
<script type="math/tex; mode=display">
\min\limits_{\mathbf{W}} J(\mathbf{W}) = \min_{\mathbf w_1, \mathbf w_2, \ldots, \mathbf w_k} -\frac{1}{N} \sum_{i=1}^{N} \sum_{k=0}^{K} \mathbf 1(y_i = k) \cdot \log \frac{e^{\mathbf w_k^{\rm T} x_i}}{\sum_{j=1}^{K} e^{\mathbf w_j^T x_i}}</script><h2 id="Perceptron"><a href="#Perceptron" class="headerlink" title="Perceptron"></a>Perceptron</h2><p>We predict based on the sign of $y$: $y = \text{sign}(f_{\mathbf w}(x)) = \text{sign}(\mathbf w^{\rm T}\mathbf x)$</p>
<p>For Perceptron the objective loss function is defined as:  </p>
<script type="math/tex; mode=display">
J_p(\mathbf{w}) = \sum_{\hat{x}_j \in \mathcal{X}^k} (-\mathbf{w}^T \hat{x}_j)</script><p>where $\mathcal{X}^k$ is the misclassified sample set at step $k$.</p>
<p>We can use gradient descent to solve for $\mathbf w^*$:  </p>
<script type="math/tex; mode=display">
\mathbf{w}_{k+1} = \mathbf{w}_k + \rho_k \sum_{x_j \in \mathcal{X}^k} (-\hat{x}_j)</script><h2 id="Support-Vector-Machine"><a href="#Support-Vector-Machine" class="headerlink" title="Support Vector Machine"></a>Support Vector Machine</h2><p>We want the optimal linear separators, that is the most robust classifier to the noisy data, meaning it has the largest margin to the training data. So we want to find the classifier with the largest margin.</p>
<h3 id="Modeling-For-Linear-Separable-Problem"><a href="#Modeling-For-Linear-Separable-Problem" class="headerlink" title="Modeling(For Linear-Separable Problem)"></a>Modeling(For Linear-Separable Problem)</h3><p>We want the margin is largest: $\max\limits_{\mathbf w, b}\rho(\mathbf w, b)$, and all the datapoints are classified correctly, that is $y_i \cdot (\mathbf w^{\rm T}\mathbf x_i + b) \geq 1$.</p>
<p>The distance between two paralleled hyperplanes is: $|b_1 - b_2| / ||a||$, and the distance between a point $\mathbf x_0$ and a hyperplane $(\mathbf w, b)$ is $|\mathbf w^{\rm T} \mathbf x_0 + b| / ||\mathbf w||$.  </p>
<p>Choose the points that are closest to the classifier, and they satisify: $|\mathbf w^{\rm T} \mathbf x_0 + b| = 1$, so that margin $\rho$ = $|\mathbf w^{\rm T} \mathbf x_1 + b| / ||\mathbf w|| + |\mathbf w^{\rm T} \mathbf x_2 + b| / ||\mathbf w|| = 2 / ||\mathbf w||$.  </p>
<p>Thus we got the Hard-margin Support Vector Machine:</p>
<script type="math/tex; mode=display">
\max\limits_{\mathbf w, b}\frac{2}{||\mathbf w||}</script><p>s.t. $y_i \cdot (\mathbf w^{\rm T}\mathbf x_i + b) \geq 1, 1 \leq i \leq n$</p>
<p>For compute convenience, we convert it into</p>
<script type="math/tex; mode=display">
\min\limits_{\mathbf w, b}\frac{1}{2}||\mathbf w||^2</script><p>s.t. $y_i \cdot (\mathbf w^{\rm T}\mathbf x_i + b) \geq 1, 1 \leq i \leq n$</p>
<h3 id="Modeling-For-Linearly-Non-Separable-Problem"><a href="#Modeling-For-Linearly-Non-Separable-Problem" class="headerlink" title="Modeling(For Linearly Non-Separable Problem)"></a>Modeling(For Linearly Non-Separable Problem)</h3><p>We add a slack that allows points to be classified on the wrong side of the decision boundary, also we add a penalty. So we got the Soft-margin SVM:</p>
<script type="math/tex; mode=display">
\min\limits_{\mathbf w, b}\frac{1}{2}||\mathbf w||^2 + C\sum_{i=1}^N \xi_i</script><p>s.t. $y_i \cdot (\mathbf w^{\rm T}\mathbf x_i + b) \geq 1 - \xi_i, 1 \leq i \leq n$</p>
<p>Using hinge-loss $\ell_{\text{hinge}}(t) = \max(1-t, 0)$, we have the final version of Soft-margin SVM:</p>
<script type="math/tex; mode=display">
\min\limits_{\mathbf w, b}\frac{1}{2}||\mathbf w||^2 + C\sum_{i=1}^N \ell_{\text{hinge}}(y_i \cdot (\mathbf w^{\rm T}\mathbf x_i + b))</script><h3 id="Optimization-For-Training"><a href="#Optimization-For-Training" class="headerlink" title="Optimization For Training"></a>Optimization For Training</h3><h4 id="Lagrangian-Function-amp-KKT-Condition"><a href="#Lagrangian-Function-amp-KKT-Condition" class="headerlink" title="Lagrangian Function &amp; KKT Condition"></a>Lagrangian Function &amp; KKT Condition</h4><p>Consider a constrained optimization problem</p>
<script type="math/tex; mode=display">
\min_{x \in \mathbb{R}^d} f(x), \text{ s.t. } g_i(x) \leq 0, \forall i = 1, \dots, n</script><p>The Lagrangian function $L(x, \mu)$ is defined as:</p>
<script type="math/tex; mode=display">
L(x, \mu) = f(x) + \sum_{j = 1}^J \mu_ig_j(x)</script><p>We have KKT conditions(necessary condition): for $1 \leq j \leq J$</p>
<ul>
<li>Primal feasibility: $g_j(x) \leq 0$</li>
<li>dual feasibility: $\mu_i \geq 0$</li>
<li>Complementary slackness: $\mu_i g_j(x^*) = 0$</li>
<li>Lagrangian optimality: $\nabla_x L(x_*, \mu) = 0$</li>
</ul>
<h4 id="Dual-Problem-For-Soft-margin-SVM"><a href="#Dual-Problem-For-Soft-margin-SVM" class="headerlink" title="Dual Problem For Soft-margin SVM"></a>Dual Problem For Soft-margin SVM</h4><p>For Soft-margin Support Vector Machine:</p>
<script type="math/tex; mode=display">
\min\limits_{\mathbf w, b}\frac{1}{2}||\mathbf w||^2 + C\sum_{i=1}^N \xi_i</script><p>s.t. $y_i \cdot (\mathbf w^{\rm T}\mathbf x_i + b) \geq 1 - \xi_i, \xi_i \geq 0, 1 \leq i \leq n$</p>
<p>We have the Lagrangian function(with $2n$ inequality constraints):</p>
<script type="math/tex; mode=display">
L(\mathbf{w}, b, \alpha, \xi, \mu) = \frac{1}{2} \|\mathbf{w}\|_2^2 + C \sum_{i=1}^{n} \xi_i + \sum_{i=1}^{n} \alpha_i [1 - \xi_i - y_i (\mathbf{w}^T \mathbf{x}_i + b)] - \sum_{i=1}^{n} \mu_i \xi_i</script><p>s.t. $\alpha_i \geq 0, \mu_i \geq 0, \, i = 1, \ldots, n$.</p>
<p>take the partial derivatives of Lagrangian w.r.t $\mathbf w, b, \xi_i$ and set to zero</p>
<script type="math/tex; mode=display">
\begin{aligned}
\frac{\partial L}{\partial \mathbf{w}} &= 0 \implies \mathbf{w} = \sum_{i=1}^{n} \alpha_i y_i \mathbf{x}_i \\
\frac{\partial L}{\partial b} &= 0 \implies \sum_{i=1}^{n} \alpha_i y_i = 0 \\
\frac{\partial L}{\partial \xi_i} &= 0 \implies C = \alpha_i + \mu_i, \, i = 1, \cdots, n \\
\end{aligned}</script><p>So that we got:</p>
<script type="math/tex; mode=display">
L(\mathbf{w}, b, \alpha, \xi, \mu) = \frac{1}{2} \|\mathbf{w}\|_2^2 + C \sum_{i=1}^{n} \xi_i + \sum_{i=1}^{n} \alpha_i [1 - \xi_i - y_i (\mathbf{w}^T \mathbf{x}_i + b)] - \sum_{i=1}^{n} \mu_i \xi_i</script><script type="math/tex; mode=display">
= \frac{1}{2} \mathbf{w}^T \mathbf{w} + \sum_{i=1}^{n} \xi_i (C - \alpha_i - \mu_i) + \sum_{i=1}^{n} \alpha_i - \sum_{i=1}^{n} \alpha_i \cdot y_i \cdot \mathbf{w}^T \mathbf{x}_i - b \sum_{i=1}^{n} \alpha_i \cdot y_i</script><script type="math/tex; mode=display">
= \frac{1}{2} \left( \sum_{i=1}^{n} \alpha_i y_i \mathbf{x}_i \right)^T \left( \sum_{j=1}^{n} \alpha_j y_j \mathbf{x}_j \right) + 0 + \sum_{i=1}^{n} \alpha_i - \sum_{i=1}^{n} \alpha_i \cdot y_i \cdot \left( \sum_{j=1}^{n} \alpha_j y_j \mathbf{x}_j \right) x_i + 0</script><script type="math/tex; mode=display">
= \frac{1}{2} \left( \sum_{i=1}^{n} \sum_{j=1}^{n} \alpha_i \alpha_j y_i y_j \mathbf{x}_i \mathbf{x}_j \right) + \sum_{i=1}^{n} \alpha_i - \left( \sum_{i=1}^{n} \sum_{j=1}^{n} \alpha_i \alpha_j y_i y_j \mathbf{x}_i \mathbf{x}_j \right)</script><script type="math/tex; mode=display">
= \sum_{i=1}^{n} \alpha_i - \frac{1}{2} \left( \sum_{i=1}^{n} \sum_{j=1}^{n} \alpha_i \alpha_j y_i y_j \mathbf{x}_i \mathbf{x}_j \right)</script><p>So we have the Dual Problem of Soft-SVM:</p>
<script type="math/tex; mode=display">
\max_{\alpha} \sum_{i=1}^{n} \alpha_i - \frac{1}{2} \sum_{i=1}^{n} \sum_{j=1}^{n} \alpha_i \alpha_j y_i y_j \mathbf{x}_i^T \mathbf{x}_j</script><p>s.t. $\sum_{i=1}^{n} \alpha_i y_i = 0, \quad 0 \leq \alpha_i \leq C, \, i = 1, \ldots, n.$</p>
<p>After solving $\alpha$, we can get $\mathbf{w} = \sum_{j=1}^n\alpha_j y_j x_j$ and $b$</p>
<h3 id="Kernel-Method-for-SVM"><a href="#Kernel-Method-for-SVM" class="headerlink" title="Kernel Method for SVM"></a>Kernel Method for SVM</h3><p>Linear SVM cannot handle linear non-separable data. So we need to map the original feature space to a higher-dimensional feature space where the training set is separable.</p>
<p>Basically we could set $x \to \phi(x)$, but calculating $x_i \dots x_j$ will cause heavy computation cost, so we use the kernel trick, that is to find a function $k(x_i, x_j) = \phi(x_i) \dots \phi(x_j)$.</p>
<p>Some commonly used kernel:</p>
<ul>
<li><p><strong>Linear Kernel:</strong></p>
<script type="math/tex; mode=display">k(\mathbf{x}, \mathbf{x}_i) = (\mathbf{x} \cdot \mathbf{x}_i)</script></li>
<li><p><strong>Polynomial Kernel:</strong></p>
<script type="math/tex; mode=display">k(\mathbf{x}, \mathbf{x}_i) = [(\mathbf{x} \cdot \mathbf{x}_i) + 1]^q</script></li>
<li><p><strong>Radial Basis Function Kernel (a.k.a. RBF kernel, Gaussian kernel):</strong></p>
<script type="math/tex; mode=display">k(\mathbf{x}, \mathbf{x}_i) = \exp \left( -\frac{\|\mathbf{x} - \mathbf{x}_i\|^2}{2\sigma^2} \right)</script></li>
<li><p><strong>Sigmoid Kernel:</strong></p>
<script type="math/tex; mode=display">k(\mathbf{x}, \mathbf{x}_i) = \tanh (v(\mathbf{x} \cdot \mathbf{x}_i) + c)</script></li>
</ul>
<p>Kernel tricks can also be applied to more algorithms, such as k-NN, LDA, etc.</p>
<h2 id="Decision-Tree"><a href="#Decision-Tree" class="headerlink" title="Decision Tree"></a>Decision Tree</h2><p>We use a tree-like structure to deal with categorical features.  </p>
<p>For each node, we find the most useful feature, that means the feature that can better divide the data on the node.</p>
<h3 id="ID3-Algorithm"><a href="#ID3-Algorithm" class="headerlink" title="ID3 Algorithm"></a>ID3 Algorithm</h3><p>We use entropy as criterion:  </p>
<script type="math/tex; mode=display">
H(D) = -\sum_{k=1}^K \frac{|C_k|}{|D|} \log \frac{|C_k|}{|D|}</script><p>A good split gives minimal weighted average entropy of child nodes:  </p>
<script type="math/tex; mode=display">
\frac{|D_1|}{|D|}H(D_1) + \frac{|D_2|}{|D|}H(D_2)</script><p>For any split, the entropy of the parent node is constant. Minimizing the weighted<br>entropy of son nodes is equivalent to maximizing the information gain (IG):</p>
<script type="math/tex; mode=display">
H(D) - \frac{|D_1|}{|D|}H(D_1) - \frac{|D_2|}{|D|}H(D_2)</script><h3 id="C4-5-Algorithm"><a href="#C4-5-Algorithm" class="headerlink" title="C4.5 Algorithm"></a>C4.5 Algorithm</h3><p>Information Gain is highly biased to multivalued features. So we use Information Gain Ratio (GR) to choose optimal feature:</p>
<script type="math/tex; mode=display">
\text{GR} = \frac{\text{Information Gain}}{\text{Intrinsic Value}}</script><p>Intrinsic Value (IV) is to punish multivalued features. For a selected feature $f$, its Intrinsic Value is:</p>
<script type="math/tex; mode=display">
IV(f) = -\sum_{k=1}^{|V|}\frac{|F_k|}{|D|} \log \frac{|F_k|}{|D|}</script><p>where $V$ is the set of all possible values of the feature $f$, and $F_k$ is the subset of $D$ where the value of the feature $A$ is $k$. Features with many possible values tend to have a large Intrinsic Value.</p>
<h3 id="Classification-and-Regression-Tree-CART"><a href="#Classification-and-Regression-Tree-CART" class="headerlink" title="Classification and Regression Tree(CART)"></a>Classification and Regression Tree(CART)</h3><p>The CART Tree muse be a binary tree.</p>
<h4 id="Regression-Tree"><a href="#Regression-Tree" class="headerlink" title="Regression Tree"></a>Regression Tree</h4><p>How to divide the regions $R = \{R_1, \dots, R_m\}$ and decide the values $V = \{v_1, \dots, v_m\}$?</p>
<p>We use minimum mean-square error over all examples $x_i$ with label $y_i$</p>
<script type="math/tex; mode=display">
\min_{R, V} l = \min_{R, V} \sum_{j = 1}^m \sum_{x_i \in R_j} (y_i - v_j)^2</script><p>Assuming that R has been determined and first find the optimal V. For a given region R_j, the value $v_j$ to minimize the loss is the average value of the labels of all samples belonging to region $R_j$:  </p>
<script type="math/tex; mode=display">
v_j = \frac{1}{|R_j|} \sum_{x_i \in R_j} y_i</script><p>Now for each feature $A$ and split threshold $a$, the parent node $R$ is split by $(A, a)$ to $R_1$ and $R_2$. We choose $(A, a) over all possible values to minimize:  </p>
<script type="math/tex; mode=display">
l(A, a) = \sum_{x_i \in R_1} (y_i - v_1(A, a))^2 + \sum_{x_i \in R_2} (y_i - v_2(A, a))^2</script><p>where $v_1(A, a)$ and $v_2(A, a)$ are described above.</p>
<h4 id="Classification-Tree"><a href="#Classification-Tree" class="headerlink" title="Classification Tree"></a>Classification Tree</h4><p>The split criteria is now Gini Index:  </p>
<script type="math/tex; mode=display">
\text{Gini}(D) = 1 - \sum_{k = 1}^K \left(\frac{|C_k|}{|D|}\right)^2</script><p>We choose the feature $A$ and the threshold $a$ over all possible values with the<br>maximal gain</p>
<script type="math/tex; mode=display">
\text{Gini}(D) - \frac{|D_1|}{|D|} \text{Gini}(D_1) - \frac{|D_2|}{|D|} \text{Gini}(D_2)</script><h2 id="Ensemble-Learning"><a href="#Ensemble-Learning" class="headerlink" title="Ensemble Learning"></a>Ensemble Learning</h2><p>Reduce the randomness (variance) by combining multiple learners.</p>
<h3 id="Bagging-Bootstrap-Aggregating"><a href="#Bagging-Bootstrap-Aggregating" class="headerlink" title="Bagging(Bootstrap Aggregating)"></a>Bagging(Bootstrap Aggregating)</h3><ol>
<li>Create $M$ bootstrap datasets</li>
<li>Train a learner on each dataset</li>
<li>Ensemble $M$ learners</li>
</ol>
<p>Uniformly sample from the original data D with replacement. The bootstrap dataset<br>has the same size as the original data D, the probability of not showing up is</p>
<script type="math/tex; mode=display">
(1-\frac{1}{n})^n \approx \frac{1}{e} \approx 0.37</script><p>We use the elements show up in $D$ but not in the bootstrap dataset as the validation set(The out-of-bag dataset).</p>
<h3 id="Random-Forest"><a href="#Random-Forest" class="headerlink" title="Random Forest"></a>Random Forest</h3><p>Ensemble decision trees (Training data with $d$ features)</p>
<ul>
<li>Create bootstrap datasets</li>
<li>During tree construction, randomly sample $K (K&lt;d)$ features as candidates for each split. (Usually choose $K = \sqrt d$)</li>
</ul>
<p>Use feature selection to make treees mutally independent and diverse.</p>
<h3 id="Boosting"><a href="#Boosting" class="headerlink" title="Boosting"></a>Boosting</h3><p>Boosting: Sequentially train learners. Current Weak learners focus more on the<br>examples that previous weak learners misclassified.</p>
<p>Weak classifiers $h_1, \cdots, h_m$ are build sequentially. $h_m$ outputs ‚Äò$+1$‚Äô for one<br>class and ‚Äò$-1$‚Äô for another class.</p>
<p>Classify by $g(x) = \text{sgn}(\sum \alpha_m h_m(x))$</p>
<h4 id="AdaBoost"><a href="#AdaBoost" class="headerlink" title="AdaBoost"></a>AdaBoost</h4><p>Core idea: give higher weights to the misclassified examples so that half of the<br>training samples come from incorrect classifications. (re-weighting)</p>
<p>Mathematical Formulation:</p>
<ol>
<li><p><strong>Weighted Error</strong>:</p>
<script type="math/tex; mode=display">
\epsilon_t = \sum_{i=1}^n w_i \cdot \mathbf 1(y_i \neq h_t(x_i))</script></li>
<li><p><strong>Alpha Calculation</strong>:</p>
<script type="math/tex; mode=display">
\alpha_t = \frac{1}{2} \ln \left( \frac{1 - \epsilon_t}{\epsilon_t} \right)</script></li>
<li><p><strong>Weight Update</strong>:</p>
<script type="math/tex; mode=display">
w_i \leftarrow w_i \exp(\alpha_t \cdot \mathbf 1(y_i \neq h_t(x_i)))</script></li>
<li><p><strong>Final Hypothesis</strong>:</p>
<script type="math/tex; mode=display">
H(x) = \text{sign} \left( \sum_{t=1}^T \alpha_t h_t(x) \right)</script></li>
</ol>
<h4 id="Gradient-Boosting"><a href="#Gradient-Boosting" class="headerlink" title="Gradient Boosting"></a>Gradient Boosting</h4><p>View boosting as an optimization problem. The criterion is to minimize the empirical loss:</p>
<script type="math/tex; mode=display">
\arg \min_{(\alpha_1, \ldots, \alpha_t, h_1, \ldots, h_t)} \sum_{i=1}^{n} l \left( y_i, \sum_{s=1}^{t} \alpha_s h_s(x) \right)</script><p>Loss function $l$ depends on the task:</p>
<ul>
<li>Cross entropy for multi-classification</li>
<li>$\text{L2}$ loss for regression</li>
</ul>
<p>We use sequential training: optimize a single model at a time, that is freeze $h_1, \cdots, h_{t-1}$ and optimize $h_t$. (Let $f_{t-1}(x) = \sum_{s=1}^{t-1} \alpha_s h_s(x)$, denoting the ensemble of $t-1$ learners.)</p>
<p>Now let‚Äôs see how to choose the $\alpha_t$ and $h_t$, we define:</p>
<script type="math/tex; mode=display">
u = (f_{t-1}(x_1), \cdots, f_{t-1}(x_n)) \\
\Delta u = (h_t(x_1), \cdots, h_t(x_n))</script><p>Consider function $F(u) = \sum_{i=1}^n l(y_i, u_i)$, then the original objective is equivalent to find a direction $\Delta u$ and step size $\alpha$ at the point $u$<br>to minimize:</p>
<script type="math/tex; mode=display">
F(u + \alpha_t \Delta u) = \sum_{i=1}^n l(y_i, u_i + \alpha \Delta u_i)</script><p>According to Gradient Descent, we could let $\delta u = \nabla_u F(u)$, thus</p>
<script type="math/tex; mode=display">
h_t(x_i) = -\frac{\partial F(u)}{\partial u_i} = -\left[ \frac{\partial l(y_i, u_i)}{\partial u_i} \right]_{u_i = f_{t-1}(x_i)}</script><p>Then how to decide $\alpha_t$? Use one-dimensional search $(y_i, x_i, f_{t-1}, h_t \text{ is fixed})$</p>
<script type="math/tex; mode=display">
\alpha_t = \arg\min_{\alpha_t} \sum_{i=1}^{n} l(y_i, f_{t-1}(x_i) + \alpha_t h_t(x_i))</script><p>For simplicity, search of optimal multiplier can be replaced by setting it a constant.  </p>
<p>In conclusion, <strong>Gradient Boosting = Gradient Descent + Boosting</strong>.</p>
<h2 id="Learning-Theory"><a href="#Learning-Theory" class="headerlink" title="Learning Theory"></a>Learning Theory</h2><h3 id="Empirical-Risk-Minimization-ERM"><a href="#Empirical-Risk-Minimization-ERM" class="headerlink" title="Empirical Risk Minimization (ERM)"></a>Empirical Risk Minimization (ERM)</h3><p>Empirical Risk: The average loss of the model $f$ on training set $\mathcal D = \{x_i, y_i\}^N_{i=1}$</p>
<script type="math/tex; mode=display">
\hat{R}(f) = \frac{1}{N} \sum_{i = 1}^N \ell(f(x_i), y_i)</script><p>Empirical Risk Minimization(ERM): The learning algorithm selects the model that minimizes the empirical risk on the training dataset.</p>
<script type="math/tex; mode=display">
\mathcal A(\mathcal D, \mathcal H) = \arg \min_{f \in \mathcal H} \hat R(f)</script><h3 id="The-Consistency-of-Learning-Process"><a href="#The-Consistency-of-Learning-Process" class="headerlink" title="The Consistency of Learning Process"></a>The Consistency of Learning Process</h3><p>We say a learning process is consistent, if the minimizer for empirical risk at<br>the infinite data limit, converges to the minimum expected risk.</p>
<h3 id="Overfitting-and-Bias-Variance-Trade-off"><a href="#Overfitting-and-Bias-Variance-Trade-off" class="headerlink" title="Overfitting and Bias-Variance Trade-off"></a>Overfitting and Bias-Variance Trade-off</h3><p>Define the Population Loss (also called Expected Risk) as</p>
<script type="math/tex; mode=display">
R(f) = \mathbb E_{(x, y) \sim u} \ell(f(x), y)</script><p>Therefore define the Generalization Gap as: $R(f) - \hat R(f)$</p>
<p>There are two important concepts of predicting model</p>
<ul>
<li>Bias: The assumptions of target model, represents the extent to which the<br>average prediction over all datasets differs from the desired function.</li>
<li>Variance: The extent of change for the model when the training data changes<br>(can be understood as ‚Äústability‚Äù to dataset change).</li>
</ul>
<p>Bias-Variance Trade-off : There is an intrinsic contradict between bias and variance. The model‚Äôs test error contains the sum of both.</p>
<p>Bias-Variance Decomposition :</p>
<p>Suppose the ground truth function is $f^*$, the data distribution is $\mu$, the algorithm $\mathcal{A}$ learns from hypothesis space $\mathcal{H}$. We use $y(x; \mathcal{D}) = \mathcal{A}(\mathcal{D}, \mathcal{H})(x)$ to denote the output of ERM model $\hat{f} = \mathcal{A}(\mathcal{D}, \mathcal{H})$ on input $x$.<br>We are interested in the learned model‚Äôs prediction error on any $x$, namely</p>
<script type="math/tex; mode=display">
[y(x; \mathcal{D}) - f^*(x)]^2 = \{y(x; \mathcal{D}) - \mathbb{E}_{\mathcal{D}}[y(x; \mathcal{D})] + \mathbb{E}_{\mathcal{D}}[y(x; \mathcal{D})] - f^*(x)\}^2</script><script type="math/tex; mode=display">
= \{y(x; \mathcal{D}) - \mathbb{E}_{\mathcal{D}}[y(x; \mathcal{D})]\}^2 + \{\mathbb{E}_{\mathcal{D}}[y(x; \mathcal{D})] - f^*(x)\}^2</script><script type="math/tex; mode=display">
- 2\{y(x; \mathcal{D}) - \mathbb{E}_{\mathcal{D}}[y(x; \mathcal{D})]\}\{\mathbb{E}_{\mathcal{D}}[y(x; \mathcal{D})] - f^*(x)\}</script><p>Taking expectation over all possible datasets $\mathcal{D}$, the last term is zero.</p>
<script type="math/tex; mode=display">
= \{\mathbb{E}_{\mathcal{D}}[y(x; \mathcal{D})] - f^*(x)\}^2 + \mathbb{E}_{\mathcal{D}}[\{y(x; \mathcal{D}) - \mathbb{E}_{\mathcal{D}}[y(x; \mathcal{D})]\}^2]</script><script type="math/tex; mode=display">
= (\text{bias})^2 + \text{variance}</script><p>Regularization refers to techniques that are used to calibrate machine learning<br>models in order to prevent overfitting, which picks a small subset of solutions<br>that are more regular (punish the parameters for behaving abnormally) to<br>reduce the variance.</p>
<h3 id="Generalization-Error-and-Regularization"><a href="#Generalization-Error-and-Regularization" class="headerlink" title="Generalization Error and Regularization"></a>Generalization Error and Regularization</h3><h4 id="VC-dimension"><a href="#VC-dimension" class="headerlink" title="VC dimension"></a>VC dimension</h4><p>VC dimension is a measure of complexity for a certain hypothesis class:<br>The largest integer $d$ for a binary classification hypothesis class $\mathcal H$, such that<br>there exists ùëë points in the input space ùí≥ that can be perfectly classified by some<br>function $h \in \mathcal H$ no matter how you assign labels for these $d$ points.</p>
<p>VC dimension characterizes the model class‚Äôs capacity for fitting random labels.</p>
<h4 id="Generalization-Error-Bound"><a href="#Generalization-Error-Bound" class="headerlink" title="Generalization Error Bound"></a>Generalization Error Bound</h4><p>If a hypothesis class $\mathcal{H}$ has VC dimension $d_{vc}$, we have a theorem that states that with probability $1 - \delta$ and $m$ samples, we can bound the generalization gap for any model $h \in \mathcal{H}$ as</p>
<script type="math/tex; mode=display">
R(h) \leq \hat{R}(h) + \sqrt{\frac{8d_{vc} \ln\left(\frac{2em}{d_{vc}}\right) + 8 \ln\left(\frac{4}{\delta}\right)}{m}}</script><h2 id="Bayesian-Decision"><a href="#Bayesian-Decision" class="headerlink" title="Bayesian Decision"></a>Bayesian Decision</h2><p>Bayesian Decision: Find an optimal classifier according to the prior probability and class-conditional probability density of the feature</p>
<p>The a priori or prior probability reflects our knowledge of how likely we expect a certain state of nature before we can actually observe said state of nature. </p>
<p>The class-conditional probability density function is the probability<br>density function $P(x|\omega)$ for our feature $x$, given that the state/class is $\omega$</p>
<p>Posterior Probability is the probability of a certain state/class given<br>our observable feature $x$: $P(\omega | x)$</p>
<p><strong>Minimum Prediction Error Principle.</strong> The optimal classifier $f(\cdot)$ should minimize the expected prediction error, defined as</p>
<script type="math/tex; mode=display">
P(\text{error}) = \int \sum_{\omega_j \neq f(x)} P(x, \omega_j) \, dx</script><p>So, for each $x$, we want</p>
<script type="math/tex; mode=display">
f(x) = \arg\min_{\omega_i} \sum_{\omega_j \neq \omega_i} P(x, \omega_j) = \arg\min_{\omega_i} P(x) - P(x, \omega_i)</script><script type="math/tex; mode=display">
f(x) = \arg\max_{\omega_i} P(x, \omega_i) = \arg\max_{\omega_i} P(\omega_i | x)</script><p>Therefore, the classifier just needs to pick the class with largest posterior probability.</p>
<p>We could use a decision threshold $\theta$ for diciding. Also we can avoid making decisions on the difficult cases in anticipation of a high error rate on those examples.</p>
<h2 id="Density-estimation"><a href="#Density-estimation" class="headerlink" title="Density estimation"></a>Density estimation</h2><p>We need a method to estimate the distribution of each feature, this is called density estimation.</p>
<h3 id="Parametric-Density-Estimation-Method"><a href="#Parametric-Density-Estimation-Method" class="headerlink" title="Parametric Density Estimation Method"></a>Parametric Density Estimation Method</h3><p>We can assume that the density function follows some form, for example:</p>
<script type="math/tex; mode=display">
P(x|\omega_i) = \frac{1}{\sqrt{2\pi}\sigma_i}e^{-\frac{(x-\mu_i)^2}{2\sigma_i^2}}</script><p>The unknown $\theta_i = (\mu_i, \sigma_i)$ is called the parameters.</p>
<h4 id="Maximum-Likelihood-Estimation-MLE"><a href="#Maximum-Likelihood-Estimation-MLE" class="headerlink" title="Maximum Likelihood Estimation (MLE)"></a>Maximum Likelihood Estimation (MLE)</h4><p>Likelihood Function: $p(x|\theta)$ measures the likelihood of a parametrized distribution to generate a sample $x$.</p>
<p>Max Likelihood Estimation (MLE): Choose the parameter ùúÉ that maximizes the<br>likelihood function for all the samples.</p>
<p>For example, if we use Gaussian to estimate $X = \{x_i\}_{i=1}^N$, MLE gives the result as</p>
<script type="math/tex; mode=display">
\mu, \sigma = \arg\max_{\mu, \sigma} \prod_{i=1}^{N} \frac{1}{\sqrt{2\pi}\sigma} e^{-\frac{(x_i - \mu)^2}{2\sigma^2}}</script><p>For the sake of simplicity, denote $H(\theta) = \ln p(X|\theta) = \sum_{i=1}^{N} \ln p(x_i|\theta)$</p>
<script type="math/tex; mode=display">
\frac{dH}{d\mu} = 0 \implies \sum_{i=1}^{N} \frac{1}{\sigma} (x_i - \mu) = 0 \implies \mu = \frac{1}{N} \sum_{i=1}^{N} x_i,</script><script type="math/tex; mode=display">
\frac{dH}{d\sigma} = 0 \implies -\sum_{i=1}^{N} \frac{1}{\sigma} + \sum_{i=1}^{N} \frac{(x_i - \mu)^2}{2\sigma^2} = 0 \implies \sigma^2 = \frac{1}{N} \sum_{i=1}^{N} (x_i - \mu)^2.</script><h3 id="Non-parametric-Density-Estimation-Method"><a href="#Non-parametric-Density-Estimation-Method" class="headerlink" title="Non-parametric Density Estimation Method"></a>Non-parametric Density Estimation Method</h3><p>Non-parametric method makes few assumptions about the form of the distribution and does not involve any parameter about the density function‚Äôs form.</p>
<p>Suppose totally we sample $N$ data, of which $K$ points are within $R$. Each data is<br>sample identically and independently. For each sample, whether it belongs to ùëÖ follows Bernoulli distribution with parameter $P_R$. We have $p(x) \approx \frac{P_R}{V} \approx \frac{K}{NV}$</p>
<p>We could apply kernel methods to it.</p>
<h2 id="Hidden-Markov-Models-HMMs"><a href="#Hidden-Markov-Models-HMMs" class="headerlink" title="Hidden Markov Models (HMMs)"></a>Hidden Markov Models (HMMs)</h2><p>Understanding Bayes‚Äô Rule:</p>
<script type="math/tex; mode=display">
p(H|E)=\frac{p(E|H)P(H)}{P(E)}</script><ul>
<li>Prior $P(H)$ : How probable was our hypothesis before observing the evidence?</li>
<li>Likelihood $p(E|H)$ : How probable is the evidence given that our hypothesis is true?</li>
<li>Marginal $P(E)$: How probable is the new evidence?</li>
</ul>
<div class="table-container">
<table>
<thead>
<tr>
<th>Notation</th>
<th>Explanation</th>
</tr>
</thead>
<tbody>
<tr>
<td>$Q = \{q_1, \ldots, q_n\}$</td>
<td>The set of $n$ hidden states.</td>
</tr>
<tr>
<td>$V = \{v_1, \ldots, v_v\}$</td>
<td>The set of all possible observed values.</td>
</tr>
<tr>
<td>$A = [a_{ij}]_{n \times n}$</td>
<td>Transition matrix. $a_{ij}$ is the probability of transitioning from state $i$ to state $j$. $\sum_{j=1}^n a_{ij} = 1 \, \forall i$.</td>
</tr>
<tr>
<td>$O = o_1 o_2 \cdots o_L$</td>
<td>Observed sequence. $o_t \in V$.</td>
</tr>
<tr>
<td>$x = x_1 x_2 \cdots x_L$</td>
<td>Hidden state sequence. $x_t \in Q$.</td>
</tr>
<tr>
<td>$E = [e_{ij}]_{n \times v}$</td>
<td>Emission probability matrix. $e_{ij} = P(o = v_j \mid x = q_i)$ is the probability of observing $v_j$ at state $q_i$. $\sum_{j=1}^V e_{ij} = 1 \, \forall i$.</td>
</tr>
<tr>
<td>$\pi = [\pi_1, \pi_2, \ldots, \pi_n]$</td>
<td>Start probability distribution. $\pi_i$ is the probability of Markov chain starting from $i$. $\sum_{i=1}^n \pi_i = 1$.</td>
</tr>
</tbody>
</table>
</div>
<p><img src="https://raw.githubusercontent.com/zcy05331/image-saver/refs/heads/main/Trad_ML/HMM%20Chain.png" alt="alt text"></p>
<h3 id="Question-1-‚Äì-Evaluation"><a href="#Question-1-‚Äì-Evaluation" class="headerlink" title="Question #1 ‚Äì Evaluation"></a>Question #1 ‚Äì Evaluation</h3><p><strong>The evaluation problem in HMM</strong>: Given a model $M$ and an observed sequence $O$, calculate the probability of the observed sequence $P(O|M)$ .</p>
<h4 id="Forward-Algorithm"><a href="#Forward-Algorithm" class="headerlink" title="Forward Algorithm"></a>Forward Algorithm</h4><p>Denote $\alpha_t(j)$ as the probability of observing $o_1 o_2 \ldots o_t$ and the hidden state at $t$ being $q_j$:</p>
<script type="math/tex; mode=display">
\alpha_t(j) = p(o_1 o_2 \ldots o_t, x_t = q_j)</script><p>Obviously, $\alpha_t(j)$ can be rewritten as:</p>
<script type="math/tex; mode=display">
\alpha_t(j) = e_j(o_t) \times \sum_{i=1}^{n} \alpha_{t-1}(i) a_{ij}</script><ol>
<li><p>Define Initial Values:</p>
<script type="math/tex; mode=display">
 \alpha_1(j) = e_j(o_1) \times \pi_j, \quad j = 1, \cdots, n</script></li>
<li><p>Iterative solving:</p>
<script type="math/tex; mode=display">
 \alpha_t(j) = e_j(o_t) \times \sum_{i=1}^{n} \alpha_{t-1}(i) a_{ij}, \quad t = 1:L</script></li>
<li><p>Obtaining results:</p>
<script type="math/tex; mode=display">
 p(O) = \sum_{i=1}^{n} \alpha_L(i)</script></li>
</ol>
<h4 id="Backward-Algorithm"><a href="#Backward-Algorithm" class="headerlink" title="Backward Algorithm"></a>Backward Algorithm</h4><p>Denote $\beta_t(j)$ as the probability of observing $o_{t+1} o_{t+2} \ldots o_L$ and the hidden state at $t$ being $q_j$:</p>
<script type="math/tex; mode=display">
\beta_t(j) = p(o_{t+1} o_{t+2} \ldots o_L \mid x_t = q_j)</script><p>Obviously, $\beta_t(j)$ can be rewritten as:</p>
<script type="math/tex; mode=display">
\beta_t(j) = \sum_{i=1}^{n} a_{ji} e_i(o_{t+1}) \beta_{t+1}(i)</script><ol>
<li><p>Define Initial Values:</p>
<script type="math/tex; mode=display">
 \beta_L(j) = 1, \quad j = 1:n \quad (L + 1 \text{ is terminal state})</script></li>
<li><p>Iterative solving:</p>
<script type="math/tex; mode=display">
 \beta_t(j) = \sum_{i=1}^{n} a_{ji} e_i(o_{t+1}) \beta_{t+1}(i), \quad t = 1:L, \quad j = 1:n</script></li>
<li><p>Obtaining results:</p>
<script type="math/tex; mode=display">
 p(O) = \sum_{i=1}^{n} \pi_i e_i(o_1) \beta_1(i)</script></li>
</ol>
<h3 id="Question-2-‚Äì-Decoding"><a href="#Question-2-‚Äì-Decoding" class="headerlink" title="Question #2 ‚Äì Decoding"></a>Question #2 ‚Äì Decoding</h3><p><strong>The decoding problem in HMM:</strong> Given a model $M$ and an observed sequence $O$, calculate the most probable hidden state sequence $\mathbf{x} = \arg\max_{\mathbf{x}} p(\mathbf{x}, O | M)$.</p>
<p>Define:</p>
<script type="math/tex; mode=display">
v_t(j) = \max_{q_1 \ldots q_{t-1}} p(q_1 \ldots q_{t-1}, o_1 \ldots o_t, x_t = q_j)</script><p>According to the recurrence relation, rewrite the above as:</p>
<script type="math/tex; mode=display">
v_t(j) = \max_{i=1}^n v_{t-1}(i) a_{ij} e_j(o_t)</script><p>Therefore, the most probable hidden state sequence is:</p>
<script type="math/tex; mode=display">
pa_t(j) = \arg\max_{i=1}^n v_{t-1}(i) a_{ij} e_j(o_t)</script><h4 id="Viterbi-Algorithm"><a href="#Viterbi-Algorithm" class="headerlink" title="Viterbi Algorithm"></a>Viterbi Algorithm</h4><ol>
<li><p>Define Initial Values:</p>
<script type="math/tex; mode=display">
 v_1(j) = e_j(o_1) \times \pi_j, \quad pa_1(j) = 0, \quad j = 1:n</script></li>
<li><p>Iterative solving:</p>
<script type="math/tex; mode=display">
 v_t(j) = \max_{i=1}^n v_{t-1}(i) a_{ij} e_j(o_t)</script><script type="math/tex; mode=display">
 pa_t(j) = \arg\max_{i=1}^n v_{t-1}(i) a_{ij} e_j(o_t)</script></li>
<li><p>Obtaining results:</p>
<script type="math/tex; mode=display">
 p^* = \max_{i=1:n} v_L(i)</script></li>
</ol>
<script type="math/tex; mode=display">
x^*_L = \arg\max_{i=1:n} v_L(i)</script><p><strong>Computational Complexity</strong>: $O(n^2 L)$</p>
<h3 id="Question-3-‚Äì-Learning"><a href="#Question-3-‚Äì-Learning" class="headerlink" title="Question #3 ‚Äì Learning"></a>Question #3 ‚Äì Learning</h3><p><strong>The learning problem in HMM</strong>: Given an observed sequence $O$, estimate the parameters of model: $M = \arg \max \limits_{M}P(M|O)$</p>
<p>For simplicity, in the following steps we only present the learning process of transition matrix $A$. (The other parameters can be learned in a similar manner.)</p>
<h4 id="Baum-Welch-Algorithm-a-special-case-of-EM-algorithm"><a href="#Baum-Welch-Algorithm-a-special-case-of-EM-algorithm" class="headerlink" title="Baum-Welch Algorithm (a special case of EM algorithm)"></a>Baum-Welch Algorithm (a special case of EM algorithm)</h4><ul>
<li><strong>Expectation Step (E-step)</strong>: Using the observed available data of the dataset, we estimate (guess) the values of the missing data with the current parameters $\theta_{\text{old}}$.</li>
<li><strong>Maximization Step (M-step)</strong>: Using complete data generated after the E-step, we update the parameters of the model.</li>
</ul>
<h5 id="E-step"><a href="#E-step" class="headerlink" title="E-step"></a>E-step</h5><p>(#$T_{ij}$ denotes the times of hidden state transitioning from $q_i$ to $q_j$)</p>
<p>Generate the guesses of #$T_{ij}$, i.e., the expected counts:</p>
<script type="math/tex; mode=display">
\text{Expected Counts} = \sum_{t=1}^{L} p(x_t = q_i, x_{t+1} = q_j \mid O, \theta_{\text{old}})</script><p>Can be estimated with Forward Algorithm and Backward Algorithm.</p>
<h5 id="M-step"><a href="#M-step" class="headerlink" title="M-step"></a>M-step</h5><p>Generate new estimations with the expected counts:</p>
<script type="math/tex; mode=display">
\hat{a}_{ij} = \frac{\sum_{t=1}^{L-1} p(x_t = q_i, x_{t+1} = q_j \mid O, \theta_{\text{old}})}{\sum_{t=1}^{L-1} \left( \sum_{j'} p(x_t = q_i, x_{t+1} = q_{j'} \mid O, \theta_{\text{old}}) \right)}</script><p>Estimation when hidden state is unknown.</p>
<p><strong>Iterative Solving</strong>: Recalculate the expected counts with newly estimated parameters (E-step). Then generate newer estimations of $\theta$ with (M-step). Repeat until convergence.</p>
<h2 id="Bayesian-Networks"><a href="#Bayesian-Networks" class="headerlink" title="Bayesian Networks"></a>Bayesian Networks</h2><h3 id="Naive-Bayes"><a href="#Naive-Bayes" class="headerlink" title="Naive Bayes"></a>Naive Bayes</h3><p>Na√Øve Bayes Assumption: Features $X_i$ are independent given class $Y$:</p>
<script type="math/tex; mode=display">
P_\theta(X_1, \ldots, X_n \mid Y) = \prod_i P_\theta(X_i \mid Y)</script><p>Inference: the label can be easily predicted with Bayes‚Äô rule</p>
<script type="math/tex; mode=display">
Y^* = \arg\max_Y \prod_i P_\theta(X_i \mid Y) P(Y)</script><p>$Y^*$ is the value that maximizes Likelihood $\times$ Prior.</p>
<p>When the number of samples is small, it is likely to encounter cases where $\text{Count}(Y = y) = 0$ or $\text{Count}(X_i = x, Y = y) = 0$. So we use Laplace Smoothing. The parameters of Na√Øve Bayes can be learned by counting:</p>
<ul>
<li>Prior:</li>
</ul>
<script type="math/tex; mode=display">
P(Y = y) = \frac{\text{Count}(Y = y) + 1}{\sum_{y'} \text{Count}(Y = y') + C}</script><ul>
<li>Observation Distribution</li>
</ul>
<script type="math/tex; mode=display">
P(X_i = x \mid Y = y) = \frac{\text{Count}(X_i = x, Y = y) + 1}{\sum_{x'} \text{Count}(X_i = x', Y = y) + S}</script><p>Here, $C$ is the number of classes, $S$ is the number of possible values that $X_i$ can take.</p>
<h3 id="Learning-amp-Decision-on-BN"><a href="#Learning-amp-Decision-on-BN" class="headerlink" title="Learning &amp; Decision on BN"></a>Learning &amp; Decision on BN</h3><h4 id="Bayesian-Network"><a href="#Bayesian-Network" class="headerlink" title="Bayesian Network"></a>Bayesian Network</h4><p><strong>BN</strong>$(G, \Theta)$: a Bayesian network</p>
<ul>
<li>$G$ is a DAG with nodes and directed edges.</li>
<li>Each node represents a random variable. Each edge represents a causal relationship/dependency.</li>
<li>$\Theta$ is the network parameters that constitute conditional probabilities.<ul>
<li>For a node $t$, its parameters are represented as $p(x_t \mid x_{\text{pa}(t)})$.</li>
</ul>
</li>
</ul>
<p>Joint probability of BN: </p>
<script type="math/tex; mode=display">
p(x) = \prod_{t=1}^{n} p(x_t \mid x_{\text{pa}(t)})</script><p>where $\text{pa}(t)$ is the set of all parent nodes of node $t$.</p>
<script type="math/tex; mode=display">
\begin{aligned}
\begin{array}{ccc}
& D \\
& \downarrow \\
& A \rightarrow B \rightarrow C
\end{array}
\end{aligned}</script><script type="math/tex; mode=display">
P(A, B, C, D) = P(A) P(D) P(B \mid A, D) P(C \mid B)</script><h4 id="Learning-on-Bayesian-Network"><a href="#Learning-on-Bayesian-Network" class="headerlink" title="Learning on Bayesian Network"></a>Learning on Bayesian Network</h4><p>Notation: Suppose BN has $n$ nodes, we use $\text{pa}(t)$ to denote the parent nodes of $t$ $(t = 1, \ldots, n)$</p>
<p>By the conditional independence of BN, we have</p>
<script type="math/tex; mode=display">
p(D \mid \Theta) = \prod_{i=1}^{N} p(x_i \mid \Theta) = \prod_{i=1}^{N} \prod_{t=1}^{n} p(x_{i,t} \mid x_{i,\text{pa}(t)}, \theta_t) = \prod_{t=1}^{n} \prod_{i=1}^{N} p(D_{i,t} \mid \theta_t)</script><script type="math/tex; mode=display">
p(\Theta) = \prod_{t=1}^{n} p(\theta_t)</script><p>Thus, the posterior becomes:</p>
<script type="math/tex; mode=display">
p(\Theta \mid D) \sim \prod_{t=1}^{n} p(D_t \mid \theta_t) p(\theta_t)</script><script type="math/tex; mode=display">
p(\theta \mid D) \sim \prod_{t=1}^{n} \prod_{c=1}^{q_t} p(D_{tc} \mid \theta_{tc}) \cdot p(\theta_{tc})</script><h5 id="Learning-BN-with-Categorical-Distribution"><a href="#Learning-BN-with-Categorical-Distribution" class="headerlink" title="Learning BN with Categorical Distribution"></a>Learning BN with Categorical Distribution</h5><p>Consider a case where each probability distribution in BN is categorical, In this case, we can model the conditional distribution of node $t$ as(We use a scalar value $c$ to represent parent nodes‚Äô states for simplicity.):</p>
<script type="math/tex; mode=display">
P(x_t = k \mid x_{\text{pa}(t)} = c) = \theta_{tck}</script><p>and the conditional probability of node $t$ can be denoted as:</p>
<script type="math/tex; mode=display">
\theta_{tc} = [\theta_{tc1}, \theta_{tc2}, \ldots, \theta_{tcK_t}], \quad \sum_{k=1}^{K_t} \theta_{tck} = 1</script><p>Categorical Distribution: </p>
<script type="math/tex; mode=display">
p = [\theta_1, \theta_2, \ldots, \theta_d], \quad \theta_i \geq 0, \quad \sum_{i} \theta_i = 1</script><p>E.g., toss a coin $(d = 2)$, roll a die $(d = 6)$</p>
<p>Count the training samples where $x_t = k, x_{\text{pa}(t)} = c$:</p>
<script type="math/tex; mode=display">
N_{tck} = \sum_{i=1}^{N} I(x_{i,t} = k, x_{i,\text{pa}(t)} = c)</script><p>According to the property of categorical distribution, we can represent the likelihood function as:</p>
<script type="math/tex; mode=display">
p(D_t \mid \theta_t) = \prod_{c=1}^{q_t} \prod_{k=1}^{K_t} \theta_{tck}^{N_{tck}} = \prod_{c=1}^{q_t} p(D_{tc} \mid \theta_{tc})</script><p>Thus the posterior can be further factorized:</p>
<script type="math/tex; mode=display">
p(\theta \mid D) \sim \prod_{t=1}^{n} p(D_t \mid \theta_t)p(\theta_t) = \prod_{t=1}^{n} \prod_{c=1}^{q_t} p(D_{tc} \mid \theta_{tc})p(\theta_{tc})</script><p>Notation:</p>
<ul>
<li>$D_{tc}$ are the sample set where the value of $x_{\text{pa}(t)}$ is $c$</li>
<li>$q_t$ is the number of possible values of $x_{\text{pa}(t)}$</li>
<li>$K_t$ is the number of possible values of $x_t$</li>
</ul>
<p>How to choose the probability distribution function for the prior $p(\theta_{tc})$? It would be highly convenient if the posterior shares the same form as the prior.</p>
<p>Conjugate Prior: A prior distribution is called a conjugate prior for a likelihood function if the posterior distribution is in the same probability distribution family as the prior.</p>
<p>The conjugate prior for the categorical distribution is the Dirichlet distribution:</p>
<p>Choosing the prior as conjugate prior ‚Äî Dirichlet distribution:</p>
<script type="math/tex; mode=display">
p(\theta_{tc}) \propto \prod_{k=1}^{K_t} \theta_{tck}^{\alpha_{tck} - 1}</script><p>$\alpha_{tck}$ are integers and are the hyperparameters of BN model.</p>
<p>In this case, the posterior can be easily derived as:</p>
<script type="math/tex; mode=display">
p(D_{tc} \mid \theta_{tc}) p(\theta_{tc}) \propto \left( \prod_{k=1}^{K_t} \theta_{tck}^{N_{tck}} \right) * \left( \prod_{k=1}^{K_t} \theta_{tck}^{\alpha_{tck} - 1} \right) = \prod_{k=1}^{K_t} \theta_{tck}^{N_{tck} + \alpha_{tck} - 1}</script><p>We can then derive an estimate of $\theta_{tck}$ by calculating the expectation:</p>
<script type="math/tex; mode=display">
\hat{\theta}_{tck} = E(\theta_{tck}) = \frac{N_{tck} + \alpha_{tck}}{\sum_{k'} (N_{tck'} + \alpha_{tck'})}</script><h2 id="K-Means-Algorithm"><a href="#K-Means-Algorithm" class="headerlink" title="K-Means Algorithm"></a>K-Means Algorithm</h2><ol>
<li><strong>Initalize</strong> cluster centers $\mu_1, \cdots, \mu_k$ randomly.</li>
<li><p><strong>Repeat</strong> until no change of cluster assignment</p>
<ol>
<li><strong>Assignment step</strong>: Assign data points to closest cluster center<script type="math/tex; mode=display">
 C_k \leftarrow \set{n \mid x_n \text{ is closest to } \mu_k}</script></li>
<li><strong>Update Step</strong>: Change the cluster center to the average of its assigned points<script type="math/tex; mode=display">
 \mu_k \leftarrow \frac{1}{|C_k|} \sum_{n \in C_k} x_n</script></li>
</ol>
</li>
</ol>
<h3 id="Optimization-View-of-K-Means"><a href="#Optimization-View-of-K-Means" class="headerlink" title="Optimization View of K-Means"></a>Optimization View of K-Means</h3><p><strong>Optimization Objective</strong>: within-cluster sum of squares (WCSS)</p>
<script type="math/tex; mode=display">
\min_{\mu, r} J_e = \sum_{k=1}^{K} \sum_{n=1}^{N} r_{n,k} \| x_n - \mu_k \|^2</script><p><strong>Step 1: Fix $\mu$, optimize $r$</strong></p>
<script type="math/tex; mode=display">
r_{n,k^*} = 1 \quad \Leftrightarrow \quad k^* = \arg\min_k \| x_n - \mu_k \|</script><p><strong>Step 2: Fix $r$, optimize $\mu$</strong></p>
<script type="math/tex; mode=display">
\mu_k^* = \frac{\sum_{n} r_{n,k} x_n}{\sum_{n} r_{n,k}} = \frac{1}{|C_k|} \sum_{n \in C_k} x_i</script><h3 id="Rule-of-Thumbs-for-initializing-k-means"><a href="#Rule-of-Thumbs-for-initializing-k-means" class="headerlink" title="Rule of Thumbs for initializing k-means"></a>Rule of Thumbs for initializing k-means</h3><ul>
<li><strong>Random Initialization</strong>: Randomly generate ùëò points in the space.</li>
<li><strong>Random Partition Initialization</strong>: Randomly group the data into ùëò clusters and<br>use their cluster center to initialize the algorithm.</li>
<li><strong>Forgy Initialization</strong>: Randomly select ùëò samples from the data.</li>
<li><strong>K-Means++</strong>: Iteratively choosing new centroids that are farthest from the existing<br>centroids.</li>
</ul>
<h3 id="How-to-tell-the-right-number-of-clusters"><a href="#How-to-tell-the-right-number-of-clusters" class="headerlink" title="How to tell the right number of clusters?"></a>How to tell the right number of clusters?</h3><p>We find the elbow point of the $J_e$ image.</p>
<h2 id="EM-Algorithm-for-Gaussian-Mixture-Model-GMM"><a href="#EM-Algorithm-for-Gaussian-Mixture-Model-GMM" class="headerlink" title="EM Algorithm for Gaussian Mixture Model (GMM)"></a>EM Algorithm for Gaussian Mixture Model (GMM)</h2><h3 id="Multivariate-Gaussian-Distribution"><a href="#Multivariate-Gaussian-Distribution" class="headerlink" title="Multivariate Gaussian Distribution"></a>Multivariate Gaussian Distribution</h3><p><strong>$d$-dimensional Multivariate Gaussian</strong>:  </p>
<script type="math/tex; mode=display">
N(x \mid \mu, \Sigma) = \frac{1}{(2\pi)^{d/2} |\Sigma|^{1/2}} \exp \left( -\frac{1}{2} (x - \mu)^T \Sigma^{-1} (x - \mu) \right)</script><ul>
<li>$\mu \in \mathbb{R}^d$ the mean vector</li>
<li>$\Sigma \in \mathbb{R}^{d \times d}$ the covariance matrix</li>
</ul>
<h4 id="MLE-of-Gaussian-Distribution"><a href="#MLE-of-Gaussian-Distribution" class="headerlink" title="MLE of Gaussian Distribution"></a>MLE of Gaussian Distribution</h4><p>The likelihood function of a given dataset $X = \{x_1, x_2, \ldots, x_N\}$:</p>
<script type="math/tex; mode=display">
p(X \mid \mu, \Sigma) = \prod_{n=1}^{N} p(x_n \mid \mu, \Sigma) = \prod_{n=1}^{N} \frac{1}{(2\pi)^{d/2} |\Sigma|^{1/2}} \exp \left( -\frac{1}{2} (x_n - \mu)^T \Sigma^{-1} (x_n - \mu) \right)</script><p>The maximum likelihood estimation (MLE) of the parameters is defined by:</p>
<script type="math/tex; mode=display">
\mu^*, \Sigma^* = \arg\max_{\mu, \Sigma} \mathcal{L}(\mu, \Sigma)</script><script type="math/tex; mode=display">
\mathcal{L}(\mu, \Sigma) = \log p(X \mid \mu, \Sigma) = \frac{N}{2} \log |\Sigma| - \frac{1}{2} \sum_{n=1}^{N} (x_n - \mu)^T \Sigma^{-1} (x_n - \mu)</script><p>The optimization problem of maximum likelihood estimation (MLE):</p>
<script type="math/tex; mode=display">
\max_{\mu, \Sigma} \mathcal{L}(\mu, \Sigma) = \frac{N}{2} \log |\Sigma| - \frac{1}{2} \sum_{n=1}^{N} (x_n - \mu)^T \Sigma^{-1} (x_n - \mu)</script><p>Solve the optimization by taking the gradient:</p>
<script type="math/tex; mode=display">
0 = \frac{\partial \mathcal{L}}{\partial \mu} = \sum_{n=1}^{N} \Sigma^{-1} (x_n - \mu) \quad \Rightarrow \quad \mu^* = \frac{1}{N} \sum_{n=1}^{N} x_n \quad \text{(Sample Mean)}</script><script type="math/tex; mode=display">
0 = \frac{\partial \mathcal{L}}{\partial \Sigma^{-1}} = \frac{N}{2} \Sigma - \frac{1}{2} \sum_{n=1}^{N} (x_n - \mu)(x_n - \mu)^T \quad \Rightarrow \quad \Sigma^* = \frac{1}{N} \sum_{n=1}^{N} (x_n - \mu^*)(x_n - \mu^*)^T \quad \text{(Sample Covariance)}</script><h3 id="Gaussian-Mixture-Model-GMM"><a href="#Gaussian-Mixture-Model-GMM" class="headerlink" title="Gaussian Mixture Model (GMM)"></a>Gaussian Mixture Model (GMM)</h3><p>A Gaussian Mixture Model (GMM) is the weighted sum of a family of Gaussians whose density function has the form:</p>
<script type="math/tex; mode=display">
p(x \mid \pi, \mu, \Sigma) = \sum_{k=1}^{K} \pi_k N(x \mid \mu_k, \Sigma_k)</script><ul>
<li>Each Gaussian $N(\mu_k, \Sigma_k)$ is called a component of GMM.</li>
<li>Scalars $\{\pi_k\}_{k=1}^{K}$ are referred to as mixing coefficients, which satisfy</li>
</ul>
<script type="math/tex; mode=display">
\sum_{k=1}^{K} \pi_k = 1</script><p>This condition ensures $p(x \mid \pi, \mu, \Sigma)$ is indeed a density function.</p>
<h3 id="Soft-Clustering-with-Mixture-Model"><a href="#Soft-Clustering-with-Mixture-Model" class="headerlink" title="Soft Clustering with Mixture Model"></a>Soft Clustering with Mixture Model</h3><script type="math/tex; mode=display">
p(z = k) = \pi_k, \quad p(x \mid z) = N(x \mid \mu_z, \Sigma_z)</script><p>By Bayes Rule, the posterior probability of $z$ given $x$ is:</p>
<script type="math/tex; mode=display">
\gamma_k \overset{\Delta}{=} p(z = k \mid x) = \frac{p(z = k, x)}{p(x)} = \frac{\pi_k N(x \mid \mu_k, \Sigma_k)}{\sum_{j=1}^{K} \pi_j N(x \mid \mu_j, \Sigma_j)}</script><p>We call $\gamma_k$ the responsibility of the $k$-th component on the data $x$.</p>
<p><strong>Probabilistic Clustering</strong>: each data point is assigned a probability distribution over the clusters.</p>
<p>‚Äú$x$ belongs to the $k$-th cluster with probability $\gamma_k$‚Äù</p>
<h3 id="MLE-for-Gaussian-Mixture-Model"><a href="#MLE-for-Gaussian-Mixture-Model" class="headerlink" title="MLE for Gaussian Mixture Model"></a>MLE for Gaussian Mixture Model</h3><p>Log-likelihood function of GMM</p>
<script type="math/tex; mode=display">
\log p(X \mid \pi, \mu, \Sigma) = \sum_{n=1}^{N} \log \left( \sum_{k=1}^{K} \pi_k N(x_n \mid \mu_k, \Sigma_k) \right)</script><p>Maximum Likelihood Estimation</p>
<script type="math/tex; mode=display">
\max_{\pi, \mu, \Sigma} \mathcal{L}(\pi, \mu, \Sigma) = \sum_{n=1}^{N} \log \left( \sum_{k=1}^{K} \pi_k N(x_n \mid \mu_k, \Sigma_k) \right)</script><p>subject to:</p>
<script type="math/tex; mode=display">
\sum_{k=1}^{K} \pi_k = 1</script><h3 id="Optimality-Condition-for-mu"><a href="#Optimality-Condition-for-mu" class="headerlink" title="Optimality Condition for $\mu$"></a>Optimality Condition for $\mu$</h3><script type="math/tex; mode=display">
N(x \mid \mu, \Sigma) = \frac{1}{(2\pi)^{d/2} |\Sigma|^{1/2}} \exp \left( -\frac{1}{2} (x - \mu)^T \Sigma^{-1} (x - \mu) \right),</script><script type="math/tex; mode=display">
\frac{\partial x^T A x}{\partial x} = (A + A^T) x</script><script type="math/tex; mode=display">
\max_{\pi, \mu, \Sigma} \mathcal{L}(\pi, \mu, \Sigma) = \sum_{n=1}^{N} \log \left( \sum_{k=1}^{K} \pi_k N(x_n \mid \mu_k, \Sigma_k) \right)</script><p>Take partial derivative with respect to $\mu_k$,</p>
<script type="math/tex; mode=display">
0 = \frac{\partial \mathcal{L}}{\partial \mu_k} = -\sum_{n=1}^{N} \frac{\pi_k N(x_n \mid \mu_k, \Sigma_k)}{\sum_j \pi_j N(x_n \mid \mu_j, \Sigma_j)} \Sigma_k^{-1} (x_n - \mu_k)</script><p>Notice that the posterior of $z_n$ (also known as responsibility $\gamma_{n,k}$) can be written as</p>
<script type="math/tex; mode=display">
\gamma_{n,k} \overset{\Delta}{=} p(z_n = k \mid x_n) = \frac{p(z_n = k) p(x_n \mid z_n = k)}{\sum_j p(z_n = j) p(x_n \mid z_n = j)} = \frac{\pi_k N(x_n \mid \mu_k, \Sigma_k)}{\sum_j \pi_j N(x_n \mid \mu_j, \Sigma_j)}</script><p>Thus</p>
<script type="math/tex; mode=display">
0 = \sum_{n=1}^{N} \gamma_{n,k} (x_n - \mu_k)</script><script type="math/tex; mode=display">
\mu_k = \frac{1}{N_k} \sum_{n=1}^{N} \gamma_{n,k} x_n, \text{ where } N_k = \sum_{n=1}^{N} \gamma_{n,k}</script><h3 id="Optimality-Condition-for-Sigma"><a href="#Optimality-Condition-for-Sigma" class="headerlink" title="Optimality Condition for $\Sigma$"></a>Optimality Condition for $\Sigma$</h3><script type="math/tex; mode=display">
\max_{\pi, \mu, \Sigma} \mathcal{L}(\pi, \mu, \Sigma) = \sum_{n=1}^{N} \log \left( \sum_{k=1}^{K} \pi_k N(x_n \mid \mu_k, \Sigma_k) \right)</script><script type="math/tex; mode=display">
\gamma_{n,k} = p(z_n = k \mid x_n) = \frac{\pi_k N(x_n \mid \mu_k, \Sigma_k)}{\sum_j \pi_j N(x_n \mid \mu_j, \Sigma_j)}, \quad N_k \overset{\Delta}{=} \sum_{n=1}^{N} \gamma_{n,k}</script><p>Similarly, take derivative with respect to $\Sigma_k$, which yields</p>
<script type="math/tex; mode=display">
0 = \frac{\partial \mathcal{L}}{\partial \Sigma_k} \quad \Rightarrow \quad \Sigma_k = \frac{1}{N_k} \sum_{n=1}^{N} \gamma_{n,k} (x_n - \mu_k)(x_n - \mu_k)^T</script><p>Responsibility-reweighted Sample Covariance</p>
<h3 id="Optimality-Condition-for-pi"><a href="#Optimality-Condition-for-pi" class="headerlink" title="Optimality Condition for $\pi$"></a>Optimality Condition for $\pi$</h3><script type="math/tex; mode=display">
\max_{\pi, \mu, \Sigma} \mathcal{L}(\pi, \mu, \Sigma) = \sum_{n=1}^{N} \log \left( \sum_{k=1}^{K} \pi_k N(x_n \mid \mu_k, \Sigma_k) \right)</script><script type="math/tex; mode=display">
\gamma_{n,k} = p(z_n = k \mid x_n) = \frac{\pi_k N(x_n \mid \mu_k, \Sigma_k)}{\sum_j \pi_j N(x_n \mid \mu_j, \Sigma_j)}, \quad N_k \overset{\Delta}{=} \sum_{n=1}^{N} \gamma_{n,k}</script><p>Constraints of mixing coefficients $\pi$: $\sum_{k=1}^{K} \pi_k = 1$</p>
<p>Introduce Lagrange multiplier:</p>
<script type="math/tex; mode=display">
\mathcal{L}' = \mathcal{L} + \lambda \left( \sum_{k=1}^{K} \pi_k - 1 \right)</script><p>Take derivative with respect to $\pi_k$, which gives</p>
<script type="math/tex; mode=display">
0 = \frac{\partial \mathcal{L}'}{\partial \pi_k} \quad \Rightarrow \quad \sum_{n=1}^{N} \frac{\gamma_{n,k}}{\pi_k} + \lambda = \frac{N_k}{\pi_k} + \lambda \quad \Rightarrow \quad \pi_k = \frac{-N_k}{\lambda}</script><p>By the constraints, we have $1 = \sum_{k=1}^{K} \pi_k = \frac{-1}{\lambda} \sum_{k=1}^{K} N_k$,</p>
<p>Also notice that</p>
<script type="math/tex; mode=display">
\sum_{k=1}^{K} N_k = \sum_{k=1}^{K} \sum_{n=1}^{N} \gamma_{n,k} = \sum_{n=1}^{N} \sum_{k=1}^{K} \gamma_{n,k} = \sum_{n=1}^{N} 1 = N</script><p>Therefore,</p>
<script type="math/tex; mode=display">
\lambda = -\sum_{k=1}^{K} N_k = -N, \quad \pi_k = \frac{N_k}{N}</script><h3 id="Expectation-Maximization-EM-Algorithm"><a href="#Expectation-Maximization-EM-Algorithm" class="headerlink" title="Expectation-Maximization (EM) Algorithm"></a>Expectation-Maximization (EM) Algorithm</h3><ol>
<li>Initialize $\pi_k, \mu_k, \Sigma_k, \quad k = 1, 2, \ldots, K$</li>
<li>E-Step: Evaluate the responsibilities using the current parameter values</li>
</ol>
<script type="math/tex; mode=display">
\gamma_{n,k} = p(z_n = 1 \mid x_n) = \frac{\pi_k N(x_n \mid \mu_k, \Sigma_k)}{\sum_j \pi_j N(x_n \mid \mu_j, \Sigma_j)}</script><ol>
<li>M-Step: Re-estimate the parameters using the current responsibilities</li>
</ol>
<script type="math/tex; mode=display">
\mu_k^{\text{new}} = \frac{1}{N_k} \sum_{n=1}^{N} \gamma_{n,k} x_n</script><script type="math/tex; mode=display">
\Sigma_k^{\text{new}} = \frac{1}{N_k} \sum_{n=1}^{N} \gamma_{n,k} (x_n - \mu_k^{\text{new}})(x_n - \mu_k^{\text{new}})^T</script><script type="math/tex; mode=display">
\pi_k^{\text{new}} = \frac{N_k}{N}</script><p>where $N_k = \sum_{n=1}^{N} \gamma_{n,k}$</p>
<ol>
<li>Return to step 2 if the convergence criterion is not satisfied.</li>
</ol>
<h2 id="Hierarchical-Clustering"><a href="#Hierarchical-Clustering" class="headerlink" title="Hierarchical Clustering"></a>Hierarchical Clustering</h2><p><strong>Distance Function</strong>: The distance function affects which pairs of clusters are merged/split and in what order.</p>
<ul>
<li><strong>Single Linkage</strong>:</li>
</ul>
<script type="math/tex; mode=display">
d(C_i, C_j) = \min_{x \in C_i, y \in C_j} d(x, y)</script><ul>
<li><strong>Complete Linkage</strong>:</li>
</ul>
<script type="math/tex; mode=display">
d(C_i, C_j) = \max_{x \in C_i, y \in C_j} d(x, y)</script><ul>
<li><strong>Average Linkage</strong>:</li>
</ul>
<script type="math/tex; mode=display">
d(C_i, C_j) = \frac{1}{|C_i| \cdot |C_j|} \sum_{x \in C_i, y \in C_j} d(x, y)</script><h3 id="Two-Types-of-Hierarchical-Clustering"><a href="#Two-Types-of-Hierarchical-Clustering" class="headerlink" title="Two Types of Hierarchical Clustering"></a>Two Types of Hierarchical Clustering</h3><ul>
<li><p><strong>Bottom-Up (Agglomerative)</strong></p>
<ul>
<li>Start with each item in its own cluster, find the best pair to merge into a new cluster.</li>
<li>Repeat until all clusters are fused together.</li>
</ul>
</li>
<li><p><strong>Top-Down (Divisive)</strong></p>
<ul>
<li>Start with one all-inclusive cluster, consider every possible way to divide the cluster in two.</li>
<li>Choose the best division and recursively operate on both sides.</li>
</ul>
</li>
</ul>
<h3 id="Agglomerative-Bottom-up-Clustering"><a href="#Agglomerative-Bottom-up-Clustering" class="headerlink" title="Agglomerative (Bottom-up) Clustering"></a>Agglomerative (Bottom-up) Clustering</h3><ol>
<li><strong>Input</strong>: cluster distance measure $d$, dataset $X = \{x_n\}_{n=1}^{N}$, number of clusters $k$</li>
<li><strong>Initialize</strong> $\mathcal{C} = \{C_i = \{x_n\} \mid x_n \in X\}$ // Each point in separate cluster</li>
<li><strong>Repeat</strong>:<ul>
<li>Find the closest pair of clusters $C_i, C_j \in \mathcal{C}$ based on distance metric $d$</li>
<li>$C_{ij} = C_i \cup C_j$ // Merge the selected clusters</li>
<li>$\mathcal{C} = (\mathcal{C} \setminus \{C_i, C_j\}) \cup \{C_{ij}\}$ // Update the clustering</li>
</ul>
</li>
<li><strong>Until</strong> $|\mathcal{C}| = k$</li>
</ol>
<p>A na√Øve implementation takes space complexity $O(N^2)$, time complexity $O(N^3)$.</p>
<h2 id="LASSO-Regression"><a href="#LASSO-Regression" class="headerlink" title="LASSO Regression"></a>LASSO Regression</h2><p><strong>LASSO (Least Absolute Shrinkage and Selection Operator)</strong>: Simply linear regression with an $\ell_1$ penalty for sparsity</p>
<script type="math/tex; mode=display">
L(w) = \sum_{i=1}^{n} \left( w^T x_i - y_i \right)^2 + C \|w\|_1</script><p>sparse solution $\leftrightarrow$ feature selection</p>
<h2 id="Principal-Component-Analysis-PCA"><a href="#Principal-Component-Analysis-PCA" class="headerlink" title="Principal Component Analysis (PCA)"></a>Principal Component Analysis (PCA)</h2><h3 id="Computing-PCA-Eigenvalue-Decomposition"><a href="#Computing-PCA-Eigenvalue-Decomposition" class="headerlink" title="Computing PCA: Eigenvalue Decomposition"></a>Computing PCA: Eigenvalue Decomposition</h3><p><strong>Objective</strong>: Maximize variance of projected data</p>
<script type="math/tex; mode=display">
\max_{\mathbf{u}_j} \mathbb{E}[(\mathbf{u}_j^T \mathbf{x})^2]</script><p>subject to $\mathbf{u}_j^T \mathbf{u}_j = 1$, $\mathbf{u}_j^T \mathbf{u}_k = 1$, $k &lt; j$</p>
<p><strong>Observation</strong>: PC $j$ is direction of the $j$-th largest eigenvector of $\frac{1}{n} \mathbf{X}^T \mathbf{X}$</p>
<p><strong>Eigenvalue Decomposition</strong>:  </p>
<script type="math/tex; mode=display">
\mathbf{U} = 
\begin{pmatrix}
\mathbf{u}_1 & \cdots & \mathbf{u}_k \\
\end{pmatrix}</script><p>are eigenvectors of $\frac{1}{n} \mathbf{X}^T \mathbf{X}$</p>
<h2 id="Manifold-Learning"><a href="#Manifold-Learning" class="headerlink" title="Manifold Learning"></a>Manifold Learning</h2><p>Geodesic distance: lines of shortest length between points on a manifold</p>

        </div>
        
        <div class="level is-size-7 is-uppercase my-post-tags">
            <div class="level-start">
                <div class="level-item">
                    <!-- <span class="is-size-6 has-text-grey has-mr-7">#</span> -->
                    <a class="my-post-tag has-link-grey -link" href="/tags/Machine-Learning/">Machine Learning</a>
                </div>
            </div>
        </div>
        
        
        
    </div>
</div>


<div class="card card-transparent">
    <div class="level post-navigation is-flex-wrap is-mobile">
        
        <div class="level-start">
            <a class="level level-item has-link-grey  article-nav-prev" href="/2024/10/18/ML-DL/">
                <i class="level-item fas fa-chevron-left"></i>
                <span class="level-item">Ê®°ÂºèËØÜÂà´‰∏éÊú∫Âô®Â≠¶‰π†Á¨îËÆ∞</span>
            </a>
        </div>
        
        
        <div class="level-end">
            <a class="level level-item has-link-grey  article-nav-next" href="/2024/03/13/CF1898E/">
                <span class="level-item">CF1898E Sofia and Strings</span>
                <i class="level-item fas fa-chevron-right"></i>
            </a>
        </div>
        
    </div>
</div>



<div class="card">
    <div class="card-content">
        <!-- <h3 class="title is-5 has-text-weight-normal">ËØÑËÆ∫</h3> -->
        
<div id="valine-thread"></div>
<script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
<script src="https://cdn.jsdelivr.net/gh/xaoxuu/volantis@1/js/volantis.min.js"></script>
<script>
    new Valine({
        el: '#valine-thread' ,
        notify: true,
        verify: true,
        app_id: 'a3s1QVgWfNVMxcHITq0cHWf1-gzGzoHsz',
        app_key: 'VX1mp6MKCsSid6Nb7Kua5fis',
        placeholder: 'qwq'
    });
</script>

    </div>
</div>
</div>
                
                




<div class="column my-sidebar is-4-tablet is-4-desktop is-4-widescreen  has-order-3 column-right is-sticky">
    
        
<div class="card widget" id="my-id-sidebar-profile">
    <div class="card-content">
        <nav class="level">
            <div class="level-item has-text-centered">
                <div>
                    <img class="image is-128x128 has-mb-6" src="/images/avatar.png" alt="little_sun">
                    
                    <p class="is-size-4 is-block">
                        little_sun
                    </p>
                    
                    
                    
                    <p class="is-size-6 is-flex is-flex-center has-text-grey">
                        <i class="fas fa-map-marker-alt has-mr-7"></i>
                        <span>Solar System</span>
                    </p>
                    
                </div>
            </div>
        </nav>
        <nav class="level is-mobile">
            <div class="level-item has-text-centered is-marginless">
                <div>
                    <p class="heading">
                        ÊñáÁ´†
                    </p>
                    <p class="title has-text-weight-normal">
                        75
                    </p>
                </div>
            </div>
            <div class="level-item has-text-centered is-marginless">
                <div>
                    <p class="heading">
                        ÂàÜÁ±ª
                    </p>
                    <p class="title has-text-weight-normal">
                        6
                    </p>
                </div>
            </div>
            <div class="level-item has-text-centered is-marginless">
                <div>
                    <p class="heading">
                        Ê†áÁ≠æ
                    </p>
                    <p class="title has-text-weight-normal">
                        61
                    </p>
                </div>
            </div>
        </nav>
        <div class="level">
            <a class="level-item button is-link is-rounded" href="http://github.com/zcy05331">
                ÂÖ≥Ê≥®Êàë
            </a>
        </div>
        
        
        <div class="level is-mobile">
            
            <a class="level-item button is-white is-marginless" target="_blank" title="Github" href="http://github.com/zcy05331">
                
                <i class="fab fa-github"></i>
                
            </a>
            
            <a class="level-item button is-white is-marginless" target="_blank" title="ÈÇÆÁÆ±" href="mailto:2939533969@qq.com">
                
                <i class="fas fa-envelope"></i>
                
            </a>
            
            <a class="level-item button is-white is-marginless" target="_blank" title="Áü•‰πé" href="https://www.zhihu.com/people/littlesun-65-87/activities">
                
                <i class="fab fa-stack-overflow"></i>
                
            </a>
            
            <a class="level-item button is-white is-marginless" target="_blank" title="QQ" href="http://wpa.qq.com/msgrd?v=3&amp;uin=2939533969">
                
                <i class="fab fa-qq"></i>
                
            </a>
            
            <a class="level-item button is-white is-marginless" target="_blank" title="Codeforces" href="https://codeforces.com/profile/little_sun">
                
                <i class="fas fa-code"></i>
                
            </a>
            
        </div>
        
    </div>
</div>
    
        
<div class="card widget" id="toc">
    <div class="card-content">
        <div class="menu">
            <h3 class="menu-label">
                ÁõÆÂΩï
            </h3>
            <ul class="menu-list"><li>
        <a class="is-flex" href="#Evaluation-Metric">
        <span class="has-mr-6">1</span>
        <span>Evaluation Metric</span>
        </a></li><li>
        <a class="is-flex" href="#k-NN">
        <span class="has-mr-6">2</span>
        <span>k-NN</span>
        </a><ul class="menu-list"><li>
        <a class="is-flex" href="#Nearest-Neighbor">
        <span class="has-mr-6">2.1</span>
        <span>Nearest Neighbor</span>
        </a></li><li>
        <a class="is-flex" href="#k-Nearest-Neighbor">
        <span class="has-mr-6">2.2</span>
        <span>k-Nearest Neighbor</span>
        </a></li><li>
        <a class="is-flex" href="#k-NN-Improvements">
        <span class="has-mr-6">2.3</span>
        <span>k-NN Improvements</span>
        </a><ul class="menu-list"><li>
        <a class="is-flex" href="#Branch-Bound-Algorithm">
        <span class="has-mr-6">2.3.1</span>
        <span>Branch-Bound Algorithm</span>
        </a></li><li>
        <a class="is-flex" href="#Edit-Nearest-Neighbor">
        <span class="has-mr-6">2.3.2</span>
        <span>Edit Nearest Neighbor</span>
        </a></li><li>
        <a class="is-flex" href="#Condensed-Nearest-Neighbor">
        <span class="has-mr-6">2.3.3</span>
        <span>Condensed Nearest Neighbor</span>
        </a></li></ul></li><li>
        <a class="is-flex" href="#The-Curse-of-Dimensionality">
        <span class="has-mr-6">2.4</span>
        <span>The Curse of Dimensionality</span>
        </a><ul class="menu-list"><li>
        <a class="is-flex" href="#Problem">
        <span class="has-mr-6">2.4.1</span>
        <span>Problem</span>
        </a></li><li>
        <a class="is-flex" href="#Solution">
        <span class="has-mr-6">2.4.2</span>
        <span>Solution</span>
        </a></li></ul></li></ul></li><li>
        <a class="is-flex" href="#Linear-Regression-Multivariate-ver">
        <span class="has-mr-6">3</span>
        <span>Linear Regression (Multivariate ver.)</span>
        </a></li><li>
        <a class="is-flex" href="#Linear-Discriminant-Analysis">
        <span class="has-mr-6">4</span>
        <span>Linear Discriminant Analysis</span>
        </a></li><li>
        <a class="is-flex" href="#Logistic-Regression">
        <span class="has-mr-6">5</span>
        <span>Logistic Regression</span>
        </a><ul class="menu-list"><li>
        <a class="is-flex" href="#Key-Concepts">
        <span class="has-mr-6">5.1</span>
        <span>Key Concepts</span>
        </a></li><li>
        <a class="is-flex" href="#Training-the-Model">
        <span class="has-mr-6">5.2</span>
        <span>Training the Model</span>
        </a></li><li>
        <a class="is-flex" href="#Generalization-to-K-classes">
        <span class="has-mr-6">5.3</span>
        <span>Generalization to K-classes</span>
        </a></li></ul></li><li>
        <a class="is-flex" href="#Perceptron">
        <span class="has-mr-6">6</span>
        <span>Perceptron</span>
        </a></li><li>
        <a class="is-flex" href="#Support-Vector-Machine">
        <span class="has-mr-6">7</span>
        <span>Support Vector Machine</span>
        </a><ul class="menu-list"><li>
        <a class="is-flex" href="#Modeling-For-Linear-Separable-Problem">
        <span class="has-mr-6">7.1</span>
        <span>Modeling(For Linear-Separable Problem)</span>
        </a></li><li>
        <a class="is-flex" href="#Modeling-For-Linearly-Non-Separable-Problem">
        <span class="has-mr-6">7.2</span>
        <span>Modeling(For Linearly Non-Separable Problem)</span>
        </a></li><li>
        <a class="is-flex" href="#Optimization-For-Training">
        <span class="has-mr-6">7.3</span>
        <span>Optimization For Training</span>
        </a><ul class="menu-list"><li>
        <a class="is-flex" href="#Lagrangian-Function-amp-KKT-Condition">
        <span class="has-mr-6">7.3.1</span>
        <span>Lagrangian Function &amp; KKT Condition</span>
        </a></li><li>
        <a class="is-flex" href="#Dual-Problem-For-Soft-margin-SVM">
        <span class="has-mr-6">7.3.2</span>
        <span>Dual Problem For Soft-margin SVM</span>
        </a></li></ul></li><li>
        <a class="is-flex" href="#Kernel-Method-for-SVM">
        <span class="has-mr-6">7.4</span>
        <span>Kernel Method for SVM</span>
        </a></li></ul></li><li>
        <a class="is-flex" href="#Decision-Tree">
        <span class="has-mr-6">8</span>
        <span>Decision Tree</span>
        </a><ul class="menu-list"><li>
        <a class="is-flex" href="#ID3-Algorithm">
        <span class="has-mr-6">8.1</span>
        <span>ID3 Algorithm</span>
        </a></li><li>
        <a class="is-flex" href="#C4-5-Algorithm">
        <span class="has-mr-6">8.2</span>
        <span>C4.5 Algorithm</span>
        </a></li><li>
        <a class="is-flex" href="#Classification-and-Regression-Tree-CART">
        <span class="has-mr-6">8.3</span>
        <span>Classification and Regression Tree(CART)</span>
        </a><ul class="menu-list"><li>
        <a class="is-flex" href="#Regression-Tree">
        <span class="has-mr-6">8.3.1</span>
        <span>Regression Tree</span>
        </a></li><li>
        <a class="is-flex" href="#Classification-Tree">
        <span class="has-mr-6">8.3.2</span>
        <span>Classification Tree</span>
        </a></li></ul></li></ul></li><li>
        <a class="is-flex" href="#Ensemble-Learning">
        <span class="has-mr-6">9</span>
        <span>Ensemble Learning</span>
        </a><ul class="menu-list"><li>
        <a class="is-flex" href="#Bagging-Bootstrap-Aggregating">
        <span class="has-mr-6">9.1</span>
        <span>Bagging(Bootstrap Aggregating)</span>
        </a></li><li>
        <a class="is-flex" href="#Random-Forest">
        <span class="has-mr-6">9.2</span>
        <span>Random Forest</span>
        </a></li><li>
        <a class="is-flex" href="#Boosting">
        <span class="has-mr-6">9.3</span>
        <span>Boosting</span>
        </a><ul class="menu-list"><li>
        <a class="is-flex" href="#AdaBoost">
        <span class="has-mr-6">9.3.1</span>
        <span>AdaBoost</span>
        </a></li><li>
        <a class="is-flex" href="#Gradient-Boosting">
        <span class="has-mr-6">9.3.2</span>
        <span>Gradient Boosting</span>
        </a></li></ul></li></ul></li><li>
        <a class="is-flex" href="#Learning-Theory">
        <span class="has-mr-6">10</span>
        <span>Learning Theory</span>
        </a><ul class="menu-list"><li>
        <a class="is-flex" href="#Empirical-Risk-Minimization-ERM">
        <span class="has-mr-6">10.1</span>
        <span>Empirical Risk Minimization (ERM)</span>
        </a></li><li>
        <a class="is-flex" href="#The-Consistency-of-Learning-Process">
        <span class="has-mr-6">10.2</span>
        <span>The Consistency of Learning Process</span>
        </a></li><li>
        <a class="is-flex" href="#Overfitting-and-Bias-Variance-Trade-off">
        <span class="has-mr-6">10.3</span>
        <span>Overfitting and Bias-Variance Trade-off</span>
        </a></li><li>
        <a class="is-flex" href="#Generalization-Error-and-Regularization">
        <span class="has-mr-6">10.4</span>
        <span>Generalization Error and Regularization</span>
        </a><ul class="menu-list"><li>
        <a class="is-flex" href="#VC-dimension">
        <span class="has-mr-6">10.4.1</span>
        <span>VC dimension</span>
        </a></li><li>
        <a class="is-flex" href="#Generalization-Error-Bound">
        <span class="has-mr-6">10.4.2</span>
        <span>Generalization Error Bound</span>
        </a></li></ul></li></ul></li><li>
        <a class="is-flex" href="#Bayesian-Decision">
        <span class="has-mr-6">11</span>
        <span>Bayesian Decision</span>
        </a></li><li>
        <a class="is-flex" href="#Density-estimation">
        <span class="has-mr-6">12</span>
        <span>Density estimation</span>
        </a><ul class="menu-list"><li>
        <a class="is-flex" href="#Parametric-Density-Estimation-Method">
        <span class="has-mr-6">12.1</span>
        <span>Parametric Density Estimation Method</span>
        </a><ul class="menu-list"><li>
        <a class="is-flex" href="#Maximum-Likelihood-Estimation-MLE">
        <span class="has-mr-6">12.1.1</span>
        <span>Maximum Likelihood Estimation (MLE)</span>
        </a></li></ul></li><li>
        <a class="is-flex" href="#Non-parametric-Density-Estimation-Method">
        <span class="has-mr-6">12.2</span>
        <span>Non-parametric Density Estimation Method</span>
        </a></li></ul></li><li>
        <a class="is-flex" href="#Hidden-Markov-Models-HMMs">
        <span class="has-mr-6">13</span>
        <span>Hidden Markov Models (HMMs)</span>
        </a><ul class="menu-list"><li>
        <a class="is-flex" href="#Question-1-‚Äì-Evaluation">
        <span class="has-mr-6">13.1</span>
        <span>Question #1 ‚Äì Evaluation</span>
        </a><ul class="menu-list"><li>
        <a class="is-flex" href="#Forward-Algorithm">
        <span class="has-mr-6">13.1.1</span>
        <span>Forward Algorithm</span>
        </a></li><li>
        <a class="is-flex" href="#Backward-Algorithm">
        <span class="has-mr-6">13.1.2</span>
        <span>Backward Algorithm</span>
        </a></li></ul></li><li>
        <a class="is-flex" href="#Question-2-‚Äì-Decoding">
        <span class="has-mr-6">13.2</span>
        <span>Question #2 ‚Äì Decoding</span>
        </a><ul class="menu-list"><li>
        <a class="is-flex" href="#Viterbi-Algorithm">
        <span class="has-mr-6">13.2.1</span>
        <span>Viterbi Algorithm</span>
        </a></li></ul></li><li>
        <a class="is-flex" href="#Question-3-‚Äì-Learning">
        <span class="has-mr-6">13.3</span>
        <span>Question #3 ‚Äì Learning</span>
        </a><ul class="menu-list"><li>
        <a class="is-flex" href="#Baum-Welch-Algorithm-a-special-case-of-EM-algorithm">
        <span class="has-mr-6">13.3.1</span>
        <span>Baum-Welch Algorithm (a special case of EM algorithm)</span>
        </a></li></ul></li></ul></li><li>
        <a class="is-flex" href="#Bayesian-Networks">
        <span class="has-mr-6">14</span>
        <span>Bayesian Networks</span>
        </a><ul class="menu-list"><li>
        <a class="is-flex" href="#Naive-Bayes">
        <span class="has-mr-6">14.1</span>
        <span>Naive Bayes</span>
        </a></li><li>
        <a class="is-flex" href="#Learning-amp-Decision-on-BN">
        <span class="has-mr-6">14.2</span>
        <span>Learning &amp; Decision on BN</span>
        </a><ul class="menu-list"><li>
        <a class="is-flex" href="#Bayesian-Network">
        <span class="has-mr-6">14.2.1</span>
        <span>Bayesian Network</span>
        </a></li><li>
        <a class="is-flex" href="#Learning-on-Bayesian-Network">
        <span class="has-mr-6">14.2.2</span>
        <span>Learning on Bayesian Network</span>
        </a></li></ul></li></ul></li><li>
        <a class="is-flex" href="#K-Means-Algorithm">
        <span class="has-mr-6">15</span>
        <span>K-Means Algorithm</span>
        </a><ul class="menu-list"><li>
        <a class="is-flex" href="#Optimization-View-of-K-Means">
        <span class="has-mr-6">15.1</span>
        <span>Optimization View of K-Means</span>
        </a></li><li>
        <a class="is-flex" href="#Rule-of-Thumbs-for-initializing-k-means">
        <span class="has-mr-6">15.2</span>
        <span>Rule of Thumbs for initializing k-means</span>
        </a></li><li>
        <a class="is-flex" href="#How-to-tell-the-right-number-of-clusters">
        <span class="has-mr-6">15.3</span>
        <span>How to tell the right number of clusters?</span>
        </a></li></ul></li><li>
        <a class="is-flex" href="#EM-Algorithm-for-Gaussian-Mixture-Model-GMM">
        <span class="has-mr-6">16</span>
        <span>EM Algorithm for Gaussian Mixture Model (GMM)</span>
        </a><ul class="menu-list"><li>
        <a class="is-flex" href="#Multivariate-Gaussian-Distribution">
        <span class="has-mr-6">16.1</span>
        <span>Multivariate Gaussian Distribution</span>
        </a><ul class="menu-list"><li>
        <a class="is-flex" href="#MLE-of-Gaussian-Distribution">
        <span class="has-mr-6">16.1.1</span>
        <span>MLE of Gaussian Distribution</span>
        </a></li></ul></li><li>
        <a class="is-flex" href="#Gaussian-Mixture-Model-GMM">
        <span class="has-mr-6">16.2</span>
        <span>Gaussian Mixture Model (GMM)</span>
        </a></li><li>
        <a class="is-flex" href="#Soft-Clustering-with-Mixture-Model">
        <span class="has-mr-6">16.3</span>
        <span>Soft Clustering with Mixture Model</span>
        </a></li><li>
        <a class="is-flex" href="#MLE-for-Gaussian-Mixture-Model">
        <span class="has-mr-6">16.4</span>
        <span>MLE for Gaussian Mixture Model</span>
        </a></li><li>
        <a class="is-flex" href="#Optimality-Condition-for-mu">
        <span class="has-mr-6">16.5</span>
        <span>Optimality Condition for $\mu$</span>
        </a></li><li>
        <a class="is-flex" href="#Optimality-Condition-for-Sigma">
        <span class="has-mr-6">16.6</span>
        <span>Optimality Condition for $\Sigma$</span>
        </a></li><li>
        <a class="is-flex" href="#Optimality-Condition-for-pi">
        <span class="has-mr-6">16.7</span>
        <span>Optimality Condition for $\pi$</span>
        </a></li><li>
        <a class="is-flex" href="#Expectation-Maximization-EM-Algorithm">
        <span class="has-mr-6">16.8</span>
        <span>Expectation-Maximization (EM) Algorithm</span>
        </a></li></ul></li><li>
        <a class="is-flex" href="#Hierarchical-Clustering">
        <span class="has-mr-6">17</span>
        <span>Hierarchical Clustering</span>
        </a><ul class="menu-list"><li>
        <a class="is-flex" href="#Two-Types-of-Hierarchical-Clustering">
        <span class="has-mr-6">17.1</span>
        <span>Two Types of Hierarchical Clustering</span>
        </a></li><li>
        <a class="is-flex" href="#Agglomerative-Bottom-up-Clustering">
        <span class="has-mr-6">17.2</span>
        <span>Agglomerative (Bottom-up) Clustering</span>
        </a></li></ul></li><li>
        <a class="is-flex" href="#LASSO-Regression">
        <span class="has-mr-6">18</span>
        <span>LASSO Regression</span>
        </a></li><li>
        <a class="is-flex" href="#Principal-Component-Analysis-PCA">
        <span class="has-mr-6">19</span>
        <span>Principal Component Analysis (PCA)</span>
        </a><ul class="menu-list"><li>
        <a class="is-flex" href="#Computing-PCA-Eigenvalue-Decomposition">
        <span class="has-mr-6">19.1</span>
        <span>Computing PCA: Eigenvalue Decomposition</span>
        </a></li></ul></li><li>
        <a class="is-flex" href="#Manifold-Learning">
        <span class="has-mr-6">20</span>
        <span>Manifold Learning</span>
        </a></li></ul>
        </div>
    </div>
</div>
<!-- <script type="text/javascript">
function myHideElement(name) {
    document.getElementById(name).style.display = 'none';
}
</script> -->

    
        	
<div class="card widget">
    <div class="card-content">
        <div class="menu">
            <h3 class="menu-label">
                ÂàÜÁ±ª
            </h3>
            <ul class="menu-list">
            <li>
        <a class="level is-marginless" href="/categories/Algorithm/">
            <span class="level-start">
                <span class="level-item">Algorithm</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">2</span>
            </span>
        </a></li><li>
        <a class="level is-marginless" href="/categories/Contest/">
            <span class="level-start">
                <span class="level-item">Contest</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">3</span>
            </span>
        </a></li><li>
        <a class="level is-marginless" href="/categories/Learning/">
            <span class="level-start">
                <span class="level-item">Learning</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">1</span>
            </span>
        </a></li><li>
        <a class="level is-marginless" href="/categories/Notes/">
            <span class="level-start">
                <span class="level-item">Notes</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">3</span>
            </span>
        </a></li><li>
        <a class="level is-marginless" href="/categories/Solution/">
            <span class="level-start">
                <span class="level-item">Solution</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">63</span>
            </span>
        </a></li><li>
        <a class="level is-marginless" href="/categories/Template/">
            <span class="level-start">
                <span class="level-item">Template</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">2</span>
            </span>
        </a></li>
            </ul>
        </div>
    </div>
</div>
    
    
</div>

            </div>
        </div>
    </section>
    <!-- <script type="text/javascript">
        myHideElement('my-id-sidebar-profile');
        myHideElement('my-id-sidebar-category');
    </script> -->
    <footer class="footer">
    <div class="container">
        <div class="level">
            <div class="level-start has-text-centered-mobile">
                <a class="footer-logo is-block has-mb-6" href="/">
                <!-- 
                    <img src="/images/logo.png" alt="ÁªèÂÖ∏Êú∫Âô®Â≠¶‰π†Á¨îËÆ∞" height="28">
                    memset0's blog
                 -->
                </a>
                <p class="is-size-7">
                    &copy; 2019 - 2024
                    <i class="fa fa-heart"></i>
                    little_sun
                </p>
                <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
                <p class="is-size-7">
                    <span>
                        <span>78.6k</span> Words
                    </span>
                    <span id="busuanzi_container_site_pv" style="display:none">
                    <span class="division">|</span>
                    <span id="busuanzi_value_site_pv"></span> Views
                    </span>
                    <span id="busuanzi_container_site_uv" style="display:none">
                    <span class="division">|</span>
                    <span id="busuanzi_value_site_uv"></span> Visitors
                    </span>
                </p>
                <p class="is-size-7">
                    Powered by little_sun
                </p>
            </div>
            <div class="level-end">
            
            </div>
        </div>
    </div>
</footer>
    <script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script>
<script>moment.locale("zh-CN");</script>


    
    
    
    <script src="/js/animation.js"></script>
    

    
    
    
    <script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script>
    <script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script>
    <script src="/js/gallery.js" defer></script>
    

    
    

<div id="outdated">
    <h6>Your browser is out-of-date!</h6>
    <p>Update your browser to view this website correctly. <a id="btnUpdateBrowser" href="http://outdatedbrowser.com/">Update
            my browser now </a></p>
    <p class="last"><a href="#" id="btnCloseUpdateBrowser" title="Close">&times;</a></p>
</div>
<script src="https://cdn.jsdelivr.net/npm/outdatedbrowser@1.1.5/outdatedbrowser/outdatedbrowser.min.js" defer></script>
<script>
    document.addEventListener("DOMContentLoaded", function () {
        outdatedBrowser({
            bgColor: '#f25648',
            color: '#ffffff',
            lowerThan: 'flex'
        });
    });
</script>


    
    
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
});

MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
});

</script>

<script async src="//cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML"></script>

    
    

<a id="back-to-top" title="ÂõûÂà∞È°∂Á´Ø" href="javascript:;">
    <i class="fas fa-chevron-up"></i>
</a>
<script src="/js/back-to-top.js" defer></script>


    
    

    
    
    
    

    
    
    


<script src="/js/main.js" defer></script>

    
    <div class="searchbox ins-search">
    <div class="searchbox-container ins-search-container">
        <div class="searchbox-input-wrapper">
            <input type="text" class="searchbox-input ins-search-input" placeholder="ÊÉ≥Ë¶ÅÊü•Êâæ‰ªÄ‰πà...">
            <span class="searchbox-close ins-close ins-selectable"><i class="fa fa-times-circle"></i></span>
        </div>
        <div class="searchbox-result-wrapper ins-section-wrapper">
            <div class="ins-section-container"></div>
        </div>
    </div>
</div>
<script>
    (function (window) {
        var INSIGHT_CONFIG = {
            TRANSLATION: {
                POSTS: 'ÊñáÁ´†',
                PAGES: 'È°µÈù¢',
                CATEGORIES: 'ÂàÜÁ±ª',
                TAGS: 'Ê†áÁ≠æ',
                UNTITLED: '(Êó†Ê†áÈ¢ò)',
            },
            CONTENT_URL: '/content.json',
        };
        window.INSIGHT_CONFIG = INSIGHT_CONFIG;
    })(window);
</script>
<script src="/js/insight.js" defer></script>
<link rel="stylesheet" href="/css/search.css">
<link rel="stylesheet" href="/css/insight.css">
    
</body>
</html>